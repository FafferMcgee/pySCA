{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of bash scripts and larger functions that wrap the primary SCA functions, and it makes things slightly hard to see. I want to tear it apart to see what each step is doing so I can understand what is going wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "The annotateMSA script provides utilities to automatically annotate sequence\n",
    "headers (for a FASTA file) with taxonomic information. Currently this can be\n",
    "done in one of two ways:\n",
    "\n",
    "    1) For Pfam alignments, annotations can be extracted from the file\n",
    "       pfamseq.txt (please download from:\n",
    "       ftp://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/database_files/pfamseq.txt.gz)\n",
    "\n",
    "    2) For Blast alignments, annotations can be added using the NCBI Entrez\n",
    "       utilities provided by BioPython. They can be based on GI or accession\n",
    "       numbers that are used to query NCBI for taxonomy information (note that\n",
    "       this approach requires a network connection).\n",
    "\n",
    "To extract GI or accession numbers, use the scripts alnParseGI.py or\n",
    "alnParseAcc.py, respectively.\n",
    "\n",
    "For both the Pfam and NCBI utilities, the process of sequence annotation *can\n",
    "be slow* (on the order of hours, particularly for NCBI entrez with larger\n",
    "alignments). However, the annotation process only needs to be run once per\n",
    "alignment.\n",
    "\n",
    "**Keyword Arguments**\n",
    "    -i, --input         Some input sequence alignment, Default: Input_MSA.fasta\n",
    "    -o, --output        Specify an output file, Default: Output_MSA.an\n",
    "    -a, --annot         Annotation method. Options are 'pfam' or 'ncbi'.\n",
    "                        Default: 'pfam'\n",
    "    -l, --idList        This argument is necessary for the 'ncbi' method.\n",
    "                        Specifies a file containing a list of GI numbers\n",
    "                        corresponding to the sequence order in the alignment; a\n",
    "                        number of \"0\" indicates that a GI number wasn't\n",
    "                        assigned for a particular sequence.\n",
    "    -g, --giList        Deprecated. Identical to '--idList' and kept to keep\n",
    "                        the CLI consistent with older versions of pySCA.\n",
    "    -p, --pfam_seq      Location of the pfamseq.txt file. Defaults to\n",
    "                        path2pfamseq (specified at the top of scaTools.py)\n",
    "    -m, --delimiter     Character(s) used for separating fields in the sequence\n",
    "                        headers of the annotated output. Default: '|'\n",
    "\n",
    "**Examples**::\n",
    "\n",
    "  annotateMSA -i PF00186_full.txt -o PF00186_full.an -a 'pfam'\n",
    "  annotateMSA -i DHFR_PEPM3.fasta -o DHFR_PEPM3.an -a 'ncbi' -l DHFR_PEPM3.gi\n",
    "\n",
    ":By: Rama Ranganathan, Kim Reynolds\n",
    ":On: 9.22.2014\n",
    "\n",
    "Copyright (C) 2015 Olivier Rivoire, Rama Ranganathan, Kimberly Reynolds\n",
    "\n",
    "This program is free software distributed under the BSD 3-clause license,\n",
    "please see the file LICENSE for details.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "from pysca import scaTools as sca\n",
    "from pysca import settings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # parse inputs\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        required=True,\n",
    "        dest=\"Input_MSA\",\n",
    "        help=\"input sequence alignment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        dest=\"output\",\n",
    "        default=\"Output.an\",\n",
    "        help=\"Outputfile name. Default: Output.an\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-a\",\n",
    "        \"--annot\",\n",
    "        dest=\"annot\",\n",
    "        default=\"pfam\",\n",
    "        help=\"Annotation method. Options are 'pfam' or 'ncbi'.\"\n",
    "        \" Default: 'pfam'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-l\",\n",
    "        \"--idList\",\n",
    "        dest=\"idList\",\n",
    "        default=None,\n",
    "        help=\"This argument is necessary for the 'ncbi' \"\n",
    "        \"method. Specifies a file containing a list of \"\n",
    "        \"GI or accession numbers corresponding to the \"\n",
    "        \"sequence order in the alignment; a number of 0 \"\n",
    "        \"indicates that one wasn't assigned for a \"\n",
    "        \"particular sequence.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-g\",\n",
    "        \"--giList\",\n",
    "        dest=\"idList\",\n",
    "        default=None,\n",
    "        help=\"Command kept for compatibility with previous \"\n",
    "        \"versions. Use '-l' or '--idList' instead.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--pfam_seq\",\n",
    "        dest=\"pfamseq\",\n",
    "        default=None,\n",
    "        help=\"Location of the pfamseq.txt file. Defaults to \"\n",
    "        \"path2pfamseq (specified in settings.py)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--pfam_db\",\n",
    "        dest=\"pfamdb\",\n",
    "        default=None,\n",
    "        help=\"Location of the pfamseq.db file. Priority over \"\n",
    "        \"pfamseq.txt file. Defaults to path2pfamseqdb \"\n",
    "        \"(specified in settings.py)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-e\",\n",
    "        \"--entrez_email\",\n",
    "        dest=\"email\",\n",
    "        default=None,\n",
    "        help=\"email address for querying Entrez web API\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--delimiter\",\n",
    "        dest=\"delimiter\",\n",
    "        default=\"|\",\n",
    "        help=\"delimiter for fields for generated FASTA files.\",\n",
    "    )\n",
    "    options = parser.parse_args()\n",
    "\n",
    "    if (options.annot != \"pfam\") & (options.annot != \"ncbi\"):\n",
    "        sys.exit(\n",
    "            \"The option -a must be set to 'pfam' or 'ncbi' - other\"\n",
    "            \" keywords are not allowed.\"\n",
    "        )\n",
    "\n",
    "    if options.annot == \"ncbi\":\n",
    "        if (options.idList is None) and (options.giList is None):\n",
    "            sys.exit(\n",
    "                \"To use NCBI Entrez annotation, you must specify a file \"\n",
    "                \"containing a list of GI numbers (see the --idList \"\n",
    "                \"argument).\"\n",
    "            )\n",
    "\n",
    "    if options.annot == \"pfam\":\n",
    "        # Annotate a Pfam alignment\n",
    "        if options.pfamdb is not None:  # default to db query over txt search\n",
    "            sca.AnnotPfamDB(\n",
    "                options.Input_MSA,\n",
    "                options.output,\n",
    "                options.pfamdb,\n",
    "                options.delimiter,\n",
    "            )\n",
    "        elif options.pfamseq is not None:\n",
    "            sca.AnnotPfam(\n",
    "                options.Input_MSA,\n",
    "                options.output,\n",
    "                options.pfamseq,\n",
    "                options.delimiter,\n",
    "            )\n",
    "        else:\n",
    "            # If no database or text file supplied to annotateMSA, then default\n",
    "            # to the files defined in settings.py.\n",
    "            if os.path.exists(settings.path2pfamseqdb):\n",
    "                sca.AnnotPfamDB(\n",
    "                    options.Input_MSA, options.output, options.delimiter\n",
    "                )\n",
    "            elif os.path.exists(settings.path2pfamseq):\n",
    "                sca.AnnotPfam(\n",
    "                    options.Input_MSA, options.output, options.delimiter\n",
    "                )\n",
    "            else:\n",
    "                sys.exit(\"No Pfam file found. Exiting.\")\n",
    "    elif options.annot == \"ncbi\":\n",
    "        # Annotate using GI numbers/NCBI Entrez\n",
    "        if options.email is None:\n",
    "            sca.AnnotNCBI(options.Input_MSA, options.output, options.idList)\n",
    "        else:\n",
    "            sca.AnnotNCBI(\n",
    "                options.Input_MSA,\n",
    "                options.output,\n",
    "                options.idList,\n",
    "                options.email,\n",
    "                options.delimiter,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "The scaProcessMSA script conducts the basic steps in multiple sequence\n",
    "alignment (MSA) pre-processing for SCA, and stores the results using the python\n",
    "tool pickle:\n",
    "\n",
    "    1)  Trim the alignment, either by truncating to a reference sequence\n",
    "        (specified with the -t flag) or by removing excessively gapped\n",
    "        positions (set to positions with more than 40% gaps)\n",
    "\n",
    "    2)  Identify/designate a reference sequence in the alignment, and create a\n",
    "        mapping of the alignment numberings to position numberings for the\n",
    "        reference sequence. The reference sequence can be specified in one of\n",
    "        four ways:\n",
    "\n",
    "            a) By supplying a PDB file - in this case, the reference sequence\n",
    "               is taken from the PDB (see the pdb kwarg)\n",
    "\n",
    "            b) By supplying a reference sequence directly (as a fasta file -\n",
    "               see the refseq kwarg)\n",
    "\n",
    "            c) By supplying the index of the reference sequence in the\n",
    "               alignment (see the refseq kwarg)\n",
    "\n",
    "            d) If no reference sequence is supplied by the user, one is\n",
    "               automatically selected using the scaTools function chooseRef.\n",
    "\n",
    "        The position numbers (for mapping the alignment) can be specified in\n",
    "        one of three ways:\n",
    "\n",
    "            a) By supplying a PDB file - in this case the alignment positions\n",
    "               are mapped to structure positions\n",
    "\n",
    "            b) By supplying a list of reference positions (see the refpos\n",
    "               kwarg)\n",
    "\n",
    "            c) If no reference positions are supplied by the user, sequential\n",
    "               numbering (starting at 1) is assumed.\n",
    "\n",
    "    3)  Filter sequences to remove highly gapped sequences, and sequences with\n",
    "        an identity below or above some minimum or maximum value to the\n",
    "        reference sequence (see the parameters kwarg)\n",
    "    4)  Filter positions to remove highly gapped positions (default 20% gaps,\n",
    "        can also be set using --parameters)\n",
    "    5)  Calculate sequence weights and write out the final alignment and other\n",
    "        variables\n",
    "\n",
    "**Key Arguments**\n",
    "     --alignment, -a   Input_MSA.fasta (the alignment to be processed,\n",
    "                       typically the headers contain taxonomic information for\n",
    "                       the sequences).\n",
    "     --pdb, -s         PDB identifier (ex: 1RX2)\n",
    "     --pdbdir, -b      directory where PDB files are stored\n",
    "     --chainID, -c     chain ID in the PDB for the reference sequence\n",
    "     --species, -f     species of the reference sequence\n",
    "     --refseq, -r      reference sequence, supplied as a fasta file\n",
    "     --refpos, -o      reference positions, supplied as a text file with one\n",
    "                       position specified per line\n",
    "     --refindex, -i    reference sequence number in the alignment, COUNTING\n",
    "                       FROM 0\n",
    "     --parameters, -p  list of parameters for filtering the alignment:\n",
    "                       [max_frac_gaps for positions, max_frac_gaps for\n",
    "                       sequences, min SID to reference seq, max SID to\n",
    "                       reference seq]\n",
    "                       default values: [0.2, 0.2, 0.2, 0.8] (see filterPos and\n",
    "                       filterSeq functions for details)\n",
    "     --selectSeqs, -n  subsample the alignment to (1.5 * the number of\n",
    "                       effective sequences) to reduce computational time,\n",
    "                       default: False\n",
    "     --truncate, -t    truncate the alignment to the positions in the reference\n",
    "                       PDB, default: False\n",
    "     --matlab, -m      write out the results of this script to a matlab\n",
    "                       workspace for further analysis\n",
    "     --dest, -d        destination for output files\n",
    "\n",
    "**Example**::\n",
    "\n",
    "  scaProcessMSA -a PF00071_full.an -s 5P21 -c A -f 'Homo sapiens'\n",
    "\n",
    ":By: Rama Ranganathan\n",
    ":On: 8.5.2014\n",
    "\n",
    "Copyright (C) 2015 Olivier Rivoire, Rama Ranganathan, Kimberly Reynolds\n",
    "\n",
    "This program is free software distributed under the BSD 3-clause license,\n",
    "please see the file LICENSE for details.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "from pysca import scaTools as sca\n",
    "from pysca import settings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parse inputs\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-a\",\n",
    "        \"--alignment\",\n",
    "        dest=\"alignment\",\n",
    "        required=True,\n",
    "        help=\"Input Sequence Alignment\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--dest\",\n",
    "        dest=\"destination\",\n",
    "        default=None,\n",
    "        help=\"specify an output directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-s\", \"--pdb\", dest=\"pdbid\", help=\"PDB identifier (ex: 1RX2)\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-b\",\n",
    "        \"--pdbdir\",\n",
    "        dest=\"pdbdir\",\n",
    "        default=None,\n",
    "        help=\"directory where PDBs are stored\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-c\",\n",
    "        \"--chainID\",\n",
    "        dest=\"chainID\",\n",
    "        default=\"A\",\n",
    "        help=\"chain ID in the PDB for the reference sequence\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-f\",\n",
    "        \"--species\",\n",
    "        dest=\"species\",\n",
    "        help=\"species of the reference sequence\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-r\",\n",
    "        \"--refseq\",\n",
    "        dest=\"refseq\",\n",
    "        help=\"reference sequence, supplied as a fasta file\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--refpos\",\n",
    "        dest=\"refpos\",\n",
    "        help=\"reference positions, supplied as a text file \"\n",
    "        \"with one position specified per line\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--refindex\",\n",
    "        dest=\"i_ref\",\n",
    "        type=int,\n",
    "        help=\"reference sequence number in the alignment, \" \"COUNTING FROM 0\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--parameters\",\n",
    "        dest=\"parameters\",\n",
    "        default=[0.2, 0.2, 0.2, 0.8],\n",
    "        type=float,\n",
    "        nargs=4,\n",
    "        help=\"list of parameters for filtering the alignment: \"\n",
    "        \"[max_frac_gaps for positions, max_frac_gaps for \"\n",
    "        \"sequences, min SID to reference seq, max SID to \"\n",
    "        \"reference seq] default values: [0.2, 0.2, 0.2, \"\n",
    "        \"0.8] (see filterPos and filterSeq functions for \"\n",
    "        \"details).\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-n\",\n",
    "        \"--selectSeqs\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"Nselect\",\n",
    "        default=False,\n",
    "        help=\"subsample the alignment to (1.5 * the number of \"\n",
    "        \"effective sequences) to reduce computational \"\n",
    "        \"time, default: False\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--truncate\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"truncate\",\n",
    "        default=False,\n",
    "        help=\"truncate the alignment to the positions in the \"\n",
    "        \"reference PDB, default: False\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--matlab\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"matfile\",\n",
    "        default=False,\n",
    "        help=\"write out the results of this script to a matlab\"\n",
    "        \" workspace for further analysis\",\n",
    "    )\n",
    "    options = parser.parse_args()\n",
    "\n",
    "    # A little bit of error checking/feedback for the user.\n",
    "    if options.i_ref is None:\n",
    "        if options.species is not None and options.pdbid is None:\n",
    "            print(\"No PDBid, ignoring species...\")\n",
    "            options.species = None\n",
    "        if options.refseq is not None and options.refpos is None:\n",
    "            print(\n",
    "                \"Using reference sequence but no position list provided! \"\n",
    "                \"Just numbering positions 1 to length(sequence)\"\n",
    "            )\n",
    "            if options.pdbid is not None:\n",
    "                print(\"And...ignoring the PDB file...\")\n",
    "                options.pdbid = None\n",
    "            options.refpos = [i + 1 for i in range(len(options.refseq))]\n",
    "        if options.refseq is not None and options.refpos is not None:\n",
    "            print(\"Using the reference sequence and position list...\")\n",
    "            if options.pdbid is not None:\n",
    "                print(\"And...ignoring the PDB file...\")\n",
    "                options.pdbid = None\n",
    "    else:\n",
    "        i_ref = options.i_ref\n",
    "\n",
    "    # Pick an output directory.\n",
    "    if options.destination is None:\n",
    "        if settings.path2output is None:\n",
    "            destination = os.getcwd()\n",
    "        else:\n",
    "            destination = os.path.abspath(settings.path2output)\n",
    "    else:\n",
    "        destination = os.path.abspath(options.destination)\n",
    "\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination)\n",
    "\n",
    "    # Set the directory where PDB files are stored.\n",
    "    if options.pdbdir is None:\n",
    "        pdbdir = settings.path2structures\n",
    "    elif os.path.exists(options.pdbdir):\n",
    "        pdbdir = options.pdbdir\n",
    "    else:\n",
    "        sys.exit(\"PDB directory '%s/' not found.\" % options.pdbdir)\n",
    "\n",
    "    # Read in initial alignment\n",
    "    headers_full, sequences_full = sca.readAlg(options.alignment)\n",
    "    print(\n",
    "        \"Loaded alignment of %i sequences, %i positions.\"\n",
    "        % (len(headers_full), len(sequences_full[0]))\n",
    "    )\n",
    "\n",
    "    if options.i_ref is not None:\n",
    "        ref_header = headers_full[options.i_ref]\n",
    "        ref_sequence = (sequences_full[options.i_ref]).replace(\".\", \"-\")\n",
    "\n",
    "    # Check the alignment and remove sequences containing non-standard amino\n",
    "    # acids\n",
    "    print(\"Checking alignment for non-standard amino acids\")\n",
    "    alg_out = list()\n",
    "    hd_out = list()\n",
    "    for i, k in enumerate(sequences_full):\n",
    "        flag = 0\n",
    "        l = k.replace(\".\", \"-\")\n",
    "        for j, aa in enumerate(l):\n",
    "            if aa not in \"ACDEFGHIKLMNPQRSTVWY-\":\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            alg_out.append(l)\n",
    "            hd_out.append(headers_full[i])\n",
    "    headers_full = hd_out\n",
    "    sequences_full = alg_out\n",
    "    print(\n",
    "        \"Aligment size after removing sequences with non-standard amino \"\n",
    "        \"acids: %i\" % (len(sequences_full))\n",
    "    )\n",
    "\n",
    "    # Do an initial trimming to remove excessively gapped positions - this is\n",
    "    # critical for building a correct ATS\n",
    "    print(\"Trimming alignment for highly gapped positions (80% or more).\")\n",
    "    alg_out, poskeep = sca.filterPos(sequences_full, [1], 0.8)\n",
    "    sequences_ori = sequences_full\n",
    "    sequences_full = alg_out\n",
    "    print(\n",
    "        \"Alignment size post-trimming: %i positions\" % len(sequences_full[0])\n",
    "    )\n",
    "\n",
    "    if options.i_ref is not None:\n",
    "        ref_sequence = \"\".join([ref_sequence[i] for i in poskeep])\n",
    "\n",
    "    # If i_ref is directly provided, we use it, ignoring all else.\n",
    "    # Otherwise, we explore the other ways of specifying a reference\n",
    "    # sequences: (1) providing a PDBid (chainID defaults to 'A'), (2)\n",
    "    # providing the protein sequence with position numbers (defaults to\n",
    "    # just sequence numbering). If none of these is provided, we just make\n",
    "    # an alignment based numbering for ats. If a PDBid is provided, there\n",
    "    # is an option to also provide species information to permit\n",
    "    # identifying the reference sequence in the MSA without use of external\n",
    "    # packages for fast pairwise alignments.\n",
    "\n",
    "    print(\"Looking for PDBs in %s\" % pdbdir)\n",
    "\n",
    "    if options.i_ref is None:\n",
    "        if options.pdbid is not None:\n",
    "            try:\n",
    "                seq_pdb, ats_pdb, dist_pdb = sca.pdbSeq(\n",
    "                    options.pdbid, options.chainID, pdbdir\n",
    "                )\n",
    "                if options.species is not None:\n",
    "                    try:\n",
    "                        print(\n",
    "                            \"Finding reference sequence using species-based\"\n",
    "                            \" best match..\"\n",
    "                        )\n",
    "                        i_ref = sca.MSAsearch(\n",
    "                            headers_full,\n",
    "                            sequences_full,\n",
    "                            seq_pdb,\n",
    "                            options.species,\n",
    "                        )\n",
    "                        options.i_ref = i_ref\n",
    "                        print(\"reference sequence index is: %i\" % (i_ref))\n",
    "                        print(headers_full[i_ref])\n",
    "                        print(sequences_full[i_ref])\n",
    "                    except BaseException as e:\n",
    "                        print(\"Error: \" + str(e))\n",
    "                        print(\n",
    "                            \"Cant find the reference sequence using\"\n",
    "                            \" species-based best_match! Using global\"\n",
    "                            \" MSAsearch...\"\n",
    "                        )\n",
    "                        try:\n",
    "                            i_ref = sca.MSAsearch(\n",
    "                                headers_full, sequences_full, seq_pdb\n",
    "                            )\n",
    "                            options.i_ref = i_ref\n",
    "                            print(\"reference sequence index is: %i\" % (i_ref))\n",
    "                            print(headers_full[i_ref])\n",
    "                            print(sequences_full[i_ref])\n",
    "                        except BaseException as e:\n",
    "                            print(\"Error: \" + str(e))\n",
    "                            sys.exit(\"Error! Can't find reference sequence...\")\n",
    "                else:\n",
    "                    try:\n",
    "                        print(\n",
    "                            \"Finding reference sequence using global\"\n",
    "                            \" MSAsearch...\"\n",
    "                        )\n",
    "                        i_ref = sca.MSAsearch(\n",
    "                            headers_full, sequences_full, seq_pdb\n",
    "                        )\n",
    "                        options.i_ref = i_ref\n",
    "                        print(\"reference sequence index is: %i\" % (i_ref))\n",
    "                        print(headers_full[i_ref])\n",
    "                        print(sequences_full[i_ref])\n",
    "                    except BaseException as e:\n",
    "                        print(\"Error: \" + str(e))\n",
    "                        sys.exit(\"Error!!  Can't find reference sequence...\")\n",
    "                sequences, ats = sca.makeATS(\n",
    "                    sequences_full, ats_pdb, seq_pdb, i_ref, options.truncate\n",
    "                )\n",
    "                dist_new = np.zeros((len(ats), len(ats)))\n",
    "                for (j, pos1) in enumerate(ats):\n",
    "                    for (k, pos2) in enumerate(ats):\n",
    "                        if k != j:\n",
    "                            if (pos1 == \"-\") or (pos2 == \"-\"):\n",
    "                                dist_new[j, k] == 1000\n",
    "                            else:\n",
    "                                ix_j = ats_pdb.index(pos1)\n",
    "                                ix_k = ats_pdb.index(pos2)\n",
    "                                dist_new[j, k] = dist_pdb[ix_j, ix_k]\n",
    "                dist_pdb = dist_new\n",
    "            except BaseException as e:\n",
    "                print(\"Error: \" + str(e))\n",
    "                sys.exit(\"Error!!! Something wrong with PDBid or path...\")\n",
    "        elif options.refseq is not None:\n",
    "            print(\n",
    "                \"Finding reference sequence using provided sequence\" \" file...\"\n",
    "            )\n",
    "            try:\n",
    "                h_tmp, s_tmp = sca.readAlg(options.refseq)\n",
    "                i_ref = sca.MSAsearch(headers_full, sequences_full, s_tmp[0])\n",
    "                options.i_ref = i_ref\n",
    "                print(\"reference sequence index is: %i\" % (i_ref))\n",
    "                print(headers_full[i_ref])\n",
    "                if options.refpos is not None:\n",
    "                    try:\n",
    "                        f = open(options.refpos, \"r\")\n",
    "                        ats_tmp = [line.rstrip(\"\\n\") for line in f]\n",
    "                        f.close()\n",
    "                    except BaseException as e:\n",
    "                        print(\"Error: \" + str(e))\n",
    "                        print(\n",
    "                            \"Error reading reference position file! Using\"\n",
    "                            \" default numbering 1 to number of positions\"\n",
    "                        )\n",
    "                        ats_tmp = [i + 1 for i in range(len(sequences[0]))]\n",
    "                else:\n",
    "                    print(\n",
    "                        \"No reference position list provided. Using\"\n",
    "                        \" default numbering 1 to number of positions\"\n",
    "                    )\n",
    "                    ats_tmp = [i + 1 for i in range(len(sequences[0]))]\n",
    "                sequences, ats = sca.makeATS(\n",
    "                    sequences_full, ats_tmp, s_tmp[0], i_ref, options.truncate\n",
    "                )\n",
    "            except BaseException as e:\n",
    "                print(\"Error: \" + str(e))\n",
    "                sys.exit(\"Error!! Can't find reference sequence...\")\n",
    "        else:\n",
    "            msa_num = sca.lett2num(sequences_full)\n",
    "            i_ref = sca.chooseRefSeq(sequences_full)\n",
    "            print(\n",
    "                \"No reference sequence given, chose as default (%i): %s\"\n",
    "                % (i_ref, headers_full[i_ref])\n",
    "            )\n",
    "            sequences = sequences_full\n",
    "            ats = [i + 1 for i in range(len(sequences[0]))]\n",
    "    else:\n",
    "        print(\"using provided reference index %i\" % (i_ref))\n",
    "        print(ref_header)\n",
    "        s_tmp = ref_sequence\n",
    "        try:\n",
    "            if options.refpos is not None:\n",
    "                f = open(options.refpos, \"r\")\n",
    "                ats_tmp = [line.rstrip(\"\\n\") for line in f]\n",
    "                f.close()\n",
    "            else:\n",
    "                print(\"here!\")\n",
    "                ats_tmp = [i + 1 for i in range(len(s_tmp))]\n",
    "            sequences, ats = sca.makeATS(\n",
    "                sequences_full, ats_tmp, s_tmp, i_ref, options.truncate\n",
    "            )\n",
    "        except BaseException as e:\n",
    "            print(\"Error: \" + str(e))\n",
    "            sys.exit(\"Error!! Can't find reference sequence...\")\n",
    "\n",
    "    # Filtering sequences and positions, calculations of effective number of\n",
    "    # seqs\n",
    "    print(\n",
    "        \"Conducting sequence and position filtering: alignment size is %i\"\n",
    "        \" seqs, %i pos\" % (len(sequences), len(sequences[0]))\n",
    "    )\n",
    "    if options.pdbid is not None:\n",
    "        print(\n",
    "            \"ATS and distmat size - ATS: %i, distmat: %i x %i\"\n",
    "            % (len(ats), len(dist_pdb), len(dist_pdb[0]))\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"ATS should also have %i positions - ATS: %i\"\n",
    "            % (len(sequences[0]), len(ats))\n",
    "        )\n",
    "\n",
    "    if i_ref is not None:\n",
    "        alg0, seqw0, seqkeep = sca.filterSeq(\n",
    "            sequences,\n",
    "            i_ref,\n",
    "            max_fracgaps=options.parameters[1],\n",
    "            min_seqid=options.parameters[2],\n",
    "            max_seqid=options.parameters[3],\n",
    "        )\n",
    "    else:\n",
    "        alg0, seqw0, seqkeep = sca.filterSeq(\n",
    "            sequences,\n",
    "            max_fracgaps=options.parameters[1],\n",
    "            min_seqid=options.parameters[2],\n",
    "            max_seqid=options.parameters[3],\n",
    "        )\n",
    "\n",
    "    headers = [headers_full[s] for s in seqkeep]\n",
    "    alg1, iposkeep = sca.filterPos(alg0, seqw0, options.parameters[0])\n",
    "    ats = [ats[i] for i in iposkeep]\n",
    "    if options.pdbid is not None:\n",
    "        distmat = dist_pdb[np.ix_(iposkeep, iposkeep)]\n",
    "    effseqsprelimit = int(seqw0.sum())\n",
    "    Nseqprelimit = len(alg1)\n",
    "    print(\n",
    "        \"After filtering: alignment size is %i seqs, %i effective seqs, %i\"\n",
    "        \" pos\" % (len(alg1), effseqsprelimit, len(alg1[0]))\n",
    "    )\n",
    "\n",
    "    # Limitation of total sequences to [1.5 * # of effective sequences] if\n",
    "    # Nselect is set to True\n",
    "    if options.Nselect:\n",
    "        seqsel = sca.randSel(\n",
    "            seqw0, int(1.5 * effseqsprelimit), [seqkeep.index(i_ref)]\n",
    "        )\n",
    "        alg = [alg1[s] for s in seqsel]\n",
    "        hd = [headers[s] for s in seqsel]\n",
    "    else:\n",
    "        alg = alg1\n",
    "        hd = headers\n",
    "\n",
    "    # Calculation of final MSA, sequence weights\n",
    "    seqw = sca.seqWeights(alg)\n",
    "    effseqs = seqw.sum()\n",
    "    msa_num = sca.lett2num(alg)\n",
    "    Nseq, Npos = msa_num.shape\n",
    "    print(\"Final alignment parameters:\")\n",
    "    print(\"Number of sequences: M = %i\" % (Nseq))\n",
    "    print(\"Number of effective sequences: M' = %i\" % (effseqs))\n",
    "    print(\"Number of alignment positions: L = %i\" % (Npos))\n",
    "\n",
    "    if options.pdbid is not None:\n",
    "        print(\"Number of positions in the ats: %i\" % (len(ats)))\n",
    "        structPos = [i for (i, k) in enumerate(ats) if k != \"-\"]\n",
    "        print(\"Number of structure positions mapped: %i\" % (len(structPos)))\n",
    "        print(\n",
    "            \"Size of the distance matrix: %i x %i\"\n",
    "            % (len(distmat), len(distmat[0]))\n",
    "        )\n",
    "\n",
    "    # Saving the important stuff. Everything is stored in a file called\n",
    "    # [MSAname]_sequence.db.  But we will also write out the final processed\n",
    "    # alignment to a fasta file.\n",
    "\n",
    "    filename = os.path.basename(options.alignment)\n",
    "    filename_noext = os.path.splitext(filename)[0]\n",
    "    f = open(\n",
    "        os.path.join(destination, filename_noext) + \"_processed\" + \".fasta\",\n",
    "        \"w\",\n",
    "    )\n",
    "    for i in range(len(alg)):\n",
    "        f.write(\">%s\\n\" % (hd[i]))\n",
    "        f.write(alg[i] + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    D = {}\n",
    "    D[\"alg\"] = alg\n",
    "    D[\"hd\"] = hd\n",
    "    D[\"msa_num\"] = msa_num\n",
    "    D[\"seqw\"] = seqw\n",
    "    D[\"Nseq\"] = Nseq\n",
    "    D[\"Npos\"] = Npos\n",
    "    D[\"ats\"] = ats\n",
    "    D[\"effseqs\"] = effseqs\n",
    "    D[\"limitseqs\"] = options.Nselect\n",
    "    D[\"NseqPrelimit\"] = Nseqprelimit\n",
    "    D[\"effseqsPrelimit\"] = effseqsprelimit\n",
    "    if options.pdbid is not None:\n",
    "        D[\"pdbid\"] = options.pdbid\n",
    "        D[\"pdb_chainID\"] = options.chainID\n",
    "        D[\"distmat\"] = distmat\n",
    "    if options.refseq is not None:\n",
    "        D[\"refseq\"] = options.refseq\n",
    "    if options.refpos is not None:\n",
    "        D[\"refpos\"] = options.refpos\n",
    "    D[\"i_ref\"] = i_ref\n",
    "    D[\"trim_parameters\"] = options.parameters\n",
    "    D[\"truncate_flag\"] = options.truncate\n",
    "\n",
    "    db_filename = os.path.join(destination, filename_noext)\n",
    "    print(\"Opening database file \" + db_filename)\n",
    "    db = {}\n",
    "    db[\"sequence\"] = D\n",
    "\n",
    "    pickle.dump(db, open(db_filename + \".db\", \"wb\"))\n",
    "\n",
    "    if options.matfile:\n",
    "        db[\"sequence\"][\"i_ref\"] = i_ref + 1  # index from 1 for MATLAB\n",
    "        savemat(db_filename, db, appendmat=True, oned_as=\"column\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "The scaCore script runs the core calculations for SCA, and stores the output\n",
    "using the Python tool pickle. These calculations can be divided into two parts:\n",
    "\n",
    "    1) Sequence correlations:\n",
    "\n",
    "        a) Compute simMat = the global sequence similarity matrix for the\n",
    "           alignment\n",
    "        b) Compute Useq and Uica = the eigenvectors (and independent\n",
    "           components) for the following sequence correlation matrices:\n",
    "\n",
    "            * unweighted (:math:`U^0`)\n",
    "            * sequence weights applied (:math:`U^1`)\n",
    "            * both sequence and position weights applied (:math:`U^2`)\n",
    "\n",
    "    2) Positional correlations:\n",
    "\n",
    "        a) Compute the single-site position weights and positional conservation\n",
    "           values (:math:`D_i` and :math:`D_i^a`)\n",
    "        b) Compute the dimension-reduced SCA correlation matrix\n",
    "           :math:`\\\\tilde{C_{ij}}`, the projected alignment :math:`tX`, and the\n",
    "           projector\n",
    "        c) Compute Ntrials of the randomized SCA matrix, and the eigenvectors\n",
    "           and eigenvalues associated with each\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "**Keyword Arguments**\n",
    "    -i               \\*.db (the database produced by running scaProcessMSA)\n",
    "    -n               norm type for dimension-reducing the sca matrix. Options\n",
    "                     are: 'spec' (the spectral norm) or 'frob' (frobenius\n",
    "                     norm). Default: frob\n",
    "    -l               lambda parameter for pseudo-counting the alignment.\n",
    "                     Default: 0.03\n",
    "    --Ntrials, -t    number of randomization trials\n",
    "    --matlab, -m     write out the results of these calculations to a MATLAB\n",
    "                     workspace for further analysis\n",
    "\n",
    "**Example**::\n",
    "\n",
    "  scaCore -i PF00071_full.db\n",
    "\n",
    ":By: Rama Ranganathan, Kim Reynolds\n",
    ":On: 8.5.2014\n",
    "\n",
    "Copyright (C) 2015 Olivier Rivoire, Rama Ranganathan, Kimberly Reynolds\n",
    "\n",
    "This program is free software distributed under the BSD 3-clause license,\n",
    "please see the file LICENSE for details.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "from scipy.io import savemat\n",
    "from pysca import scaTools as sca\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Parse inputs\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-i\" \"--input\",\n",
    "        dest=\"inputdb\",\n",
    "        required=True,\n",
    "        help=\"database from running scaProcessMSA\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\" \"--output\",\n",
    "        dest=\"outputdb\",\n",
    "        default=None,\n",
    "        help=\"output file for core calculations\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-n\",\n",
    "        dest=\"norm\",\n",
    "        default=\"frob\",\n",
    "        help=\"norm type for dimension-reducing the sca matrix.\"\n",
    "        \"Options are: 'spec' (the spectral norm) or \"\n",
    "        \"'frob' (frobenius norm). Default: frob\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--Ntrials\",\n",
    "        dest=\"Ntrials\",\n",
    "        default=10,\n",
    "        type=int,\n",
    "        help=\"number of randomization trials\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-l\",\n",
    "        dest=\"lbda\",\n",
    "        default=0.03,\n",
    "        type=float,\n",
    "        help=\"lambda parameter for pseudo-counting the \"\n",
    "        \"alignment. Default: 0.03\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-q\",\n",
    "        dest=\"kseq\",\n",
    "        default=30,\n",
    "        type=int,\n",
    "        help=\"number of eigenvectors to computes in sequence matrix. \"\n",
    "        \"Default: 30\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-c\",\n",
    "        dest=\"kica\",\n",
    "        default=15,\n",
    "        type=int,\n",
    "        help=\"number of independent components to compute from sequence \"\n",
    "        \"alignment matrix. Default: 15\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--matlab\",\n",
    "        dest=\"matfile\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"write out the results of these calculations to \"\n",
    "        \"a MATLAB workspace for further analysis.\",\n",
    "    )\n",
    "    options = parser.parse_args()\n",
    "\n",
    "    if (options.norm != \"frob\") & (options.norm != \"spec\"):\n",
    "        sys.exit(\n",
    "            \"The option -n must be set to 'frob' or 'spec' - other \"\n",
    "            \"keywords are not allowed.\"\n",
    "        )\n",
    "\n",
    "    # extract the necessary stuff from the database...\n",
    "    db_in = pickle.load(open(options.inputdb, \"rb\"))\n",
    "    D_in = db_in[\"sequence\"]\n",
    "\n",
    "    msa_num = D_in[\"msa_num\"]\n",
    "    seqw = D_in[\"seqw\"]\n",
    "    Nseq = D_in[\"Nseq\"]\n",
    "    Npos = D_in[\"Npos\"]\n",
    "    ats = D_in[\"ats\"]\n",
    "    hd = D_in[\"hd\"]\n",
    "\n",
    "    # sequence analysis\n",
    "    print(\"Computing the sequence projections.\")\n",
    "    Useq, Uica = sca.seqProj(\n",
    "        msa_num, seqw, kseq=options.kseq, kica=options.kica\n",
    "    )\n",
    "\n",
    "    print(\"Computing sequence similarity matrix.\")\n",
    "    simMat = sca.seqSim(msa_num)\n",
    "\n",
    "    # SCA calculations\n",
    "    print(\"Computing the SCA conservation and correlation values.\")\n",
    "    Wia, Dia, Di = sca.posWeights(msa_num, seqw, options.lbda)\n",
    "    Csca, tX, Proj = sca.scaMat(msa_num, seqw, options.norm, options.lbda)\n",
    "\n",
    "    # Matrix randomizations\n",
    "    print(\"Computing matrix randomizations...\")\n",
    "    start = time.time()\n",
    "    Vrand, Lrand, Crand = sca.randomize(\n",
    "        msa_num, options.Ntrials, seqw, options.lbda\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(\n",
    "        \"Randomizations complete, %i trials, time: %.1f minutes\"\n",
    "        % (options.Ntrials, (end - start) / 60)\n",
    "    )\n",
    "\n",
    "    # saving...\n",
    "    if options.outputdb is None:\n",
    "        fn = os.path.basename(options.inputdb)\n",
    "        output_path = os.path.abspath(os.path.dirname(options.inputdb))\n",
    "    else:\n",
    "        fn = os.path.basename(options.outputdb)\n",
    "        output_path = os.path.abspath(os.path.dirname(options.outputdb))\n",
    "    fn_noext = os.path.splitext(fn)[0]\n",
    "\n",
    "    D = {}\n",
    "    D[\"Useq\"] = Useq\n",
    "    D[\"Uica\"] = Uica\n",
    "    D[\"simMat\"] = simMat\n",
    "    D[\"lbda\"] = options.lbda\n",
    "    D[\"Dia\"] = Dia\n",
    "    D[\"Di\"] = Di\n",
    "    D[\"Csca\"] = Csca\n",
    "    D[\"tX\"] = tX\n",
    "    D[\"Proj\"] = Proj\n",
    "    D[\"Ntrials\"] = options.Ntrials\n",
    "    D[\"Vrand\"] = Vrand\n",
    "    D[\"Lrand\"] = Lrand\n",
    "    D[\"Crand\"] = Crand\n",
    "\n",
    "    db = {}\n",
    "    db[\"sequence\"] = D_in\n",
    "    db[\"sca\"] = D\n",
    "\n",
    "    print(\n",
    "        \"Calculations complete, writing to database file \"\n",
    "        + os.path.join(output_path, fn_noext)\n",
    "    )\n",
    "    pickle.dump(db, open(os.path.join(output_path, fn_noext) + \".db\", \"wb\"))\n",
    "\n",
    "    if options.matfile:\n",
    "        savemat(\n",
    "            os.path.join(output_path, fn_noext) + \".mat\",\n",
    "            db,\n",
    "            appendmat=True,\n",
    "            oned_as=\"column\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\"\"\"\n",
    "The scaSectorID script does the preliminaries of sector identification and\n",
    "stores the outputs using the python tool pickle:\n",
    "\n",
    "    1) Chooses :math:`k_{max}` (the number of significant eigenmodes) by\n",
    "       comparison of the :math:`\\\\tilde{C_{ij}}` eigenspectrum to that for the\n",
    "       randomized matrices\n",
    "    2) Rotates the top :math:`k_{max}` eigenvectors using independent\n",
    "       components analysis\n",
    "    3) Defines the amino acid positions that significantly contribute to each\n",
    "       of the independent components (ICs) by empirically fitting each IC to\n",
    "       the t-distribution and selecting positions with greater than a specified\n",
    "       cutoff (default: p=0.95) on the CDF.\n",
    "    4) Assign positions into groups based on the independent component with\n",
    "       which it has the greatest degree of co-evolution.\n",
    "\n",
    "**Key Arguments**\n",
    "    --input, -i      \\*.db (the database produced by running scaCore)\n",
    "    --kpos, -k       number of significant eigenmodes for analysis (the default\n",
    "                     is to automatically choose using the eigenspectrum)\n",
    "    --cutoff, -p     empirically chosen cutoff for selecting AA positions with\n",
    "                     a significant contribution to each IC, Default = 0.95\n",
    "    --matlab, -m     write out the results of this script to a matlab workspace\n",
    "                     for further analysis\n",
    "\n",
    "**Example**::\n",
    "\n",
    "  scaSectorID -i PF00071_full.db\n",
    "\n",
    ":By: Kim Reynolds\n",
    ":On: 8.19.2014\n",
    "\n",
    "Copyright (C) 2015 Olivier Rivoire, Rama Ranganathan, Kimberly Reynolds\n",
    "\n",
    "This program is free software distributed under the BSD 3-clause license,\n",
    "please see the file LICENSE for details.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "from pysca import scaTools as sca\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parse inputs\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--input\",\n",
    "        dest=\"inputdb\",\n",
    "        required=True,\n",
    "        help=\"database from running scaCore\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\" \"--output\",\n",
    "        dest=\"outputdb\",\n",
    "        default=None,\n",
    "        help=\"output file for sector calculations\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-k\",\n",
    "        \"--kpos\",\n",
    "        dest=\"kpos\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"number of significant eigenmodes for analysis \"\n",
    "        \"(the default is to automatically choose using \"\n",
    "        \"the eigenspectrum)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--cutoff\",\n",
    "        dest=\"cutoff\",\n",
    "        type=float,\n",
    "        default=0.95,\n",
    "        help=\"number of significant eigenmodes for analysis \"\n",
    "        \"(the default is to automatically choose using \"\n",
    "        \"the eigenspectrum)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\",\n",
    "        \"--matlab\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"matfile\",\n",
    "        default=False,\n",
    "        help=\"write out the results of this script to a \"\n",
    "        \"matlab workspace for further analysis\",\n",
    "    )\n",
    "    options = parser.parse_args()\n",
    "\n",
    "    # extract the necessary stuff from the database...\n",
    "    db_in = pickle.load(open(options.inputdb, \"rb\"))\n",
    "    D_seq = db_in[\"sequence\"]\n",
    "    D_sca = db_in[\"sca\"]\n",
    "\n",
    "    msa_num = D_seq[\"msa_num\"]\n",
    "    seqw = D_seq[\"seqw\"]\n",
    "    lbda = D_sca[\"lbda\"]\n",
    "    Csca = D_sca[\"Csca\"]\n",
    "    tX = D_sca[\"tX\"]\n",
    "    Lrand = D_sca[\"Lrand\"]\n",
    "\n",
    "    # run the calculations\n",
    "    Vsca, Lsca = sca.eigenVect(Csca)\n",
    "\n",
    "    if options.kpos == 0:\n",
    "        kpos = sca.chooseKpos(Lsca, Lrand)\n",
    "    else:\n",
    "        kpos = options.kpos\n",
    "    print(\"Selected kpos=%i significant eigenmodes.\" % kpos)\n",
    "    Vpica, Wpica = sca.rotICA(Vsca, kmax=kpos)\n",
    "    ics, icsize, sortedpos, cutoff, scaled_pd, pd = sca.icList(\n",
    "        Vpica, kpos, Csca, p_cut=options.cutoff\n",
    "    )\n",
    "\n",
    "    Usca = tX.dot(Vsca[:, :kpos]).dot(np.diag(1 / np.sqrt(Lsca[:kpos])))\n",
    "    Upica = Wpica.dot(Usca.T).T\n",
    "    for k in range(Upica.shape[1]):\n",
    "        Upica[:, k] /= np.sqrt(Upica[:, k].T.dot(Upica[:, k]))\n",
    "    Usica, Wsica = sca.rotICA(Usca, kmax=kpos)\n",
    "\n",
    "    # saving...\n",
    "    if options.outputdb is None:\n",
    "        fn = os.path.basename(options.inputdb)\n",
    "        output_path = os.path.abspath(os.path.dirname(options.inputdb))\n",
    "    else:\n",
    "        fn = os.path.basename(options.outputdb)\n",
    "        output_path = os.path.abspath(os.path.dirname(options.outputdb))\n",
    "    fn_noext = os.path.splitext(fn)[0]\n",
    "\n",
    "    D = {}\n",
    "    D[\"Vsca\"] = Vsca\n",
    "    D[\"Lsca\"] = Lsca\n",
    "    D[\"kpos\"] = kpos\n",
    "    D[\"Vpica\"] = Vpica\n",
    "    D[\"Wpica\"] = Wpica\n",
    "    D[\"Usca\"] = Usca\n",
    "    D[\"Upica\"] = Upica\n",
    "    D[\"Usica\"] = Usica\n",
    "    D[\"Wsica\"] = Wsica\n",
    "    D[\"ics\"] = ics\n",
    "    D[\"icsize\"] = icsize\n",
    "    D[\"sortedpos\"] = sortedpos\n",
    "    D[\"cutoff\"] = cutoff\n",
    "    D[\"scaled_pd\"] = scaled_pd\n",
    "    D[\"pd\"] = pd\n",
    "\n",
    "    db = {}\n",
    "    db[\"sequence\"] = D_seq\n",
    "    db[\"sca\"] = D_sca\n",
    "    db[\"sector\"] = D\n",
    "\n",
    "    print(\n",
    "        \"Calculations complete, writing to database file \"\n",
    "        + os.path.join(output_path, fn_noext)\n",
    "    )\n",
    "    pickle.dump(db, open(os.path.join(output_path, fn_noext) + \".db\", \"wb\"))\n",
    "\n",
    "    if options.matfile:\n",
    "        # increment indices by 1 for MATLAB\n",
    "        db[\"sector\"][\"sortedpos\"] = [pos + 1 for pos in D[\"sortedpos\"]]\n",
    "        for ic in ics:\n",
    "            ic.items = [item + 1 for item in ic.items]\n",
    "        db[\"sector\"][\"ics\"] = ics\n",
    "        savemat(\n",
    "            os.path.join(output_path, fn_noext) + \".mat\",\n",
    "            db,\n",
    "            appendmat=True,\n",
    "            oned_as=\"column\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\"\"\"\n",
    "pySCA - A SCA toolbox in Python\n",
    "\n",
    ":By:\n",
    "\n",
    "| Olivier Rivoire (olivier.rivoire@ujf-grenoble.fr)\n",
    "| Kimberly Reynolds (kimberly.reynolds@utsouthwestern.edu)\n",
    "| Rama Ranganathan (rama.ranganathan@utsouthwestern.edu)\n",
    "\n",
    ":On:  August 2014\n",
    ":version: 6.1\n",
    "\n",
    "Copyright (C) 2015 Olivier Rivoire, Rama Ranganathan, Kimberly Reynolds\n",
    "\n",
    "This program is free software distributed under the BSD 3-clause license,\n",
    "please see the file LICENSE for details.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import copy\n",
    "import time\n",
    "import random as rand\n",
    "import colorsys\n",
    "import sqlite3\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from scipy.sparse import csr_matrix as sparsify\n",
    "from scipy.stats import t\n",
    "from scipy.stats import scoreatpercentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio import pairwise2\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import Entrez\n",
    "\n",
    "from pysca import settings\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# CLASSES\n",
    "\n",
    "\n",
    "class Unit:\n",
    "    \"\"\"\n",
    "    A class for units (sectors, sequence families, etc.)\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "      :name:  string describing the unit (ex: 'firmicutes')\n",
    "      :items: set of member items (ex: indices for all firmicutes\n",
    "              sequence in an alignment)\n",
    "      :col:   color code associated to the unit (for plotting)\n",
    "      :vect:  an additional vector describing the member items (ex: a list\n",
    "              of sequence weights)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.name = \"\"\n",
    "        self.items = set()\n",
    "        self.col = 0\n",
    "        self.vect = 0\n",
    "\n",
    "\n",
    "class Annot:\n",
    "    \"\"\"\n",
    "    A class for annotating sequences\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "      :desc:    description (often the sequence header)\n",
    "      :species: species string\n",
    "      :taxo:    taxonomy string\n",
    "      :seq:     sequence\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, descr, species, taxo, seq=\"\"):\n",
    "        self.descr = descr\n",
    "        self.species = species\n",
    "        self.taxo = taxo\n",
    "        self.seq = seq\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# ALIGNMENT PROCESSING\n",
    "\n",
    "\n",
    "def readAlg(filename):\n",
    "    \"\"\"\n",
    "    Read in a multiple sequence alignment in FASTA format, and return the\n",
    "    headers and sequences.\n",
    "\n",
    "    headers, sequences = readAlg(filename)\n",
    "    \"\"\"\n",
    "\n",
    "    filelines = open(filename, \"r\").readlines()\n",
    "    headers = list()\n",
    "    sequences = list()\n",
    "    notfirst = 0\n",
    "    for line in filelines:\n",
    "        if line[0] == \">\":\n",
    "            if notfirst > 0:\n",
    "                sequences.append(seq.replace(\"\\n\", \"\").upper())\n",
    "            headers.append(line[1:].replace(\"\\n\", \"\"))\n",
    "            seq = \"\"\n",
    "            notfirst = 1\n",
    "        elif line != \"\\n\":\n",
    "            seq += line\n",
    "    sequences.append(seq.replace(\"\\n\", \"\").upper())\n",
    "    return headers, sequences\n",
    "\n",
    "\n",
    "def parseAlgHeader(header, delimiter=\"|\"):\n",
    "    \"\"\"\n",
    "    Use this instead of splitting on the \"|\" delimiter if the \"|\" character\n",
    "    shows up inside one of the fields.\n",
    "\n",
    "    Run this function on a single header, not all the headers returned in the\n",
    "    list from readAlg.\n",
    "\n",
    "    header_fields = readAlg(headers)\n",
    "    \"\"\"\n",
    "\n",
    "    header_fields = header.split(delimiter)\n",
    "    idx1 = [i for i in range(len(header_fields)) if \"{\" in header_fields[i]]\n",
    "    idx2 = [i for i in range(len(header_fields)) if \"}\" in header_fields[i]]\n",
    "\n",
    "    idx_loss = 0\n",
    "    for i, j in zip(idx1, idx2):\n",
    "        header_fields[(i - idx_loss) : (j + 1 - idx_loss)] = [\n",
    "            delimiter.join(header_fields[(i - idx_loss) : (j + 1 - idx_loss)])\n",
    "        ]\n",
    "        idx_loss = idx_loss + (j - i)\n",
    "\n",
    "    return header_fields\n",
    "\n",
    "\n",
    "def AnnotPfam(\n",
    "    pfam_in, pfam_out, pfam_seq=settings.path2pfamseq, delimiter=\"|\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Phylogenetic annotation of a Pfam alignment (in FASTA format) using\n",
    "    information from pfamseq.txt. The output is a FASTA file containing\n",
    "    phylogenetic annotations in the header (to be parsed with '|' as a\n",
    "    delimiter).\n",
    "\n",
    "    Note: the headers for the original alignment take the form >AAA/x-y.  If\n",
    "    two entries have same AAA but correspond to different sequences only one of\n",
    "    the two sequences will be represented (twice) in the output - this should\n",
    "    however not practically be an issue.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      - input Pfam sequence alignment\n",
    "      - output file name for the annotated Pfam alignment\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      - `pfam_seq` = path to the file pfamseq.txt\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Beginning annotation\")\n",
    "\n",
    "    # Reads the pfam headers and sequences:\n",
    "    headers, sequences = readAlg(pfam_in)\n",
    "    pfamseq_ids = [h.split(\"/\")[0] for h in headers]\n",
    "\n",
    "    # Reads the sequence information for those sequences:\n",
    "    seq_info = dict()\n",
    "    with open(pfam_seq) as fp:\n",
    "        for line in fp:\n",
    "            pf_id = line.split(\"\\t\")[1]\n",
    "            if pf_id in pfamseq_ids:\n",
    "                seq_info[pf_id] = line\n",
    "                pfamseq_ids.remove(pf_id)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Writes in output file:\n",
    "    if os.path.dirname(pfam_out):\n",
    "        Path(os.path.dirname(pfam_out)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(pfam_out, \"w\") as f:\n",
    "        pfamseq_ids = [h.split(\"/\")[0] for h in headers]\n",
    "        for i, key in enumerate(pfamseq_ids):\n",
    "            print(\"Current step %i, key %s\" % (i, key))\n",
    "            try:\n",
    "                info = seq_info[key]\n",
    "            except BaseException as e:\n",
    "                print(\"Error: \" + str(e))\n",
    "                info = \"\\t\".join([\"unknown\"] * 10 + [\"unknown;unknown\"])\n",
    "            # this f.write line works with older pfamseq.txt files (release 4 and\n",
    "            # before, was used to annotate the tutorial alignments\n",
    "            # f.write('>%s|%s|%s|%s\\n' % (key, info.split('\\t')[6],\n",
    "            #         info.split('\\t')[9],\n",
    "            #         ','.join([name.strip()\n",
    "            #                   for name in info.split('\\t')[10].split(';')])))\n",
    "            # this f.write line works with the new version of pfamseq.txt\n",
    "            f.write(\n",
    "                \">%s%s%s%s%s%s%s\\n\"\n",
    "                % (\n",
    "                    key,\n",
    "                    delimiter,\n",
    "                    info.split(\"\\t\")[5],\n",
    "                    delimiter,\n",
    "                    info.split(\"\\t\")[8],\n",
    "                    delimiter,\n",
    "                    \",\".join(\n",
    "                        [\n",
    "                            name.strip()\n",
    "                            for name in info.split(\"\\t\")[9].split(\";\")\n",
    "                        ]\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "            f.write(\"%s\\n\" % (sequences[i]))\n",
    "    print(\"Elapsed time: %.1f min\" % ((end_time - start_time) / 60))\n",
    "\n",
    "\n",
    "def AnnotPfamDB(\n",
    "    pfam_in, pfam_out, pfam_db=settings.path2pfamseqdb, delimiter=\"|\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Phylogenetic annotation of a Pfam alignment (in FASTA format) using\n",
    "    information from pfamseq.txt. The output is a FASTA file containing\n",
    "    phylogenetic annotations in the header (to be parsed with '|' as a\n",
    "    delimiter).\n",
    "\n",
    "    Note: the headers for the original alignment take the form >AAA/x-y.  If\n",
    "    two entries have same AAA but correspond to different sequences only one of\n",
    "    the two sequences will be represented (twice) in the output - this should\n",
    "    however not practically be an issue.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      - input Pfam sequence alignment\n",
    "      - output file name for the annotated Pfam alignment\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      - `pfam_db` = path to the file pfamseq.db\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Beginning annotation\")\n",
    "\n",
    "    # Reads the pfam headers and sequences:\n",
    "    headers, sequences = readAlg(pfam_in)\n",
    "    pfamseq_ids = [h.split(\"/\")[0] for h in headers]\n",
    "\n",
    "    # Reads the sequence information for those sequences:\n",
    "    seq_info = []\n",
    "    with sqlite3.connect(pfam_db) as conn:\n",
    "        c = conn.cursor()\n",
    "        for pfamseq_id in pfamseq_ids:\n",
    "            c.execute(\n",
    "                \"SELECT pfamseq_id,description,species,taxonomy \"\n",
    "                \"FROM pfamseq WHERE pfamseq_id = ?\",\n",
    "                (pfamseq_id,),\n",
    "            )\n",
    "            res = c.fetchall()\n",
    "            if res:\n",
    "                row = [field for match in res for field in match]\n",
    "            else:\n",
    "                c.execute(\n",
    "                    \"SELECT pfamseq_acc,description,species,taxonomy \"\n",
    "                    \"FROM pfamseq WHERE pfamseq_acc = ?\",\n",
    "                    (pfamseq_id,),\n",
    "                )\n",
    "                res = c.fetchall()\n",
    "                if res:\n",
    "                    row = [field for match in res for field in match]\n",
    "                else:\n",
    "                    row = [pfamseq_id, \"unknown\", \"unknown\", \"unknown\"]\n",
    "            seq_info.append(row)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Write to output file:\n",
    "    if os.path.dirname(pfam_out):\n",
    "        Path(os.path.dirname(pfam_out)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(pfam_out, \"w\") as f:\n",
    "        for i, row in enumerate(seq_info):\n",
    "            f.write(\n",
    "                \">%s%s%s%s%s%s%s\\n\"\n",
    "                % (\n",
    "                    row[0],\n",
    "                    delimiter,\n",
    "                    row[1],\n",
    "                    delimiter,\n",
    "                    row[2],\n",
    "                    delimiter,\n",
    "                    \",\".join([taxon.strip() for taxon in row[3].split(\";\")]),\n",
    "                )\n",
    "            )\n",
    "            f.write(\"%s\\n\" % sequences[i])\n",
    "    print(\"Elapsed time: %.1f min\" % ((end_time - start_time) / 60))\n",
    "\n",
    "\n",
    "def AnnotNCBI(\n",
    "    alg_in, alg_out, id_list, email=settings.entrezemail, delimiter=\"|\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Phylogenetic annotation of a NCBI alignment (in FASTA format). Uses GI\n",
    "    numbers or accession numbers embedded in the headers of the multiple\n",
    "    sequences alignment. Requires that all the fields are consistent for all\n",
    "    sequences.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      - input NCBI sequence alignment\n",
    "      - output file name for the annotated alignment\n",
    "      - file containing a list of sequences identifiers\n",
    "      - type of sequence identifier used\n",
    "      - email address for querying database\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      - `alg_in` = path to the input alignment file\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Beginning annotation\")\n",
    "    Entrez.email = email  # PLEASE use your email! (see settings.py)\n",
    "\n",
    "    # Annotate using GI or accession numbers.\n",
    "    seq_ids = open(id_list, \"r\").read().splitlines()\n",
    "\n",
    "    # esummary will not return blank lines when a 0 ID is used for the query.\n",
    "    # The result is that returned list will not have the same number of\n",
    "    # elements as the number of sequences. A workaround is to filter out the\n",
    "    # unidentified sequences (id = 0), store the indices where they occur, run\n",
    "    # esummary with the remainder, and then add the indices back to the list.\n",
    "    zeros_idx = [key for key, value in enumerate(seq_ids) if value == \"0\"]\n",
    "    seq_ids = list(filter(lambda x: x != \"0\", seq_ids))\n",
    "\n",
    "    # Group ID numbers into blocks, and submit each block as a query to the web\n",
    "    # API.\n",
    "    id_blocksize = 10\n",
    "    id_blocks = [\n",
    "        seq_ids[x : x + id_blocksize]\n",
    "        for x in range(0, len(seq_ids), id_blocksize)\n",
    "    ]\n",
    "\n",
    "    taxIDs = list()\n",
    "    start = time.time()\n",
    "    for i, id_block in enumerate(id_blocks):\n",
    "        handle = Entrez.esummary(db=\"protein\", id=\",\".join(id_block))\n",
    "        time.sleep(0.33)\n",
    "        taxonList = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        for j, taxon in enumerate(taxonList):\n",
    "            if taxon[\"TaxId\"]:\n",
    "                taxIDs.append(str(taxon[\"TaxId\"]))\n",
    "            else:\n",
    "                print(\"TaxId not found for %s\" % id_block[j])\n",
    "                taxIDs.append(\"1\")\n",
    "    end = time.time()\n",
    "\n",
    "    # Add back taxID of 1 (the root of the taxonomic tree) for sequences\n",
    "    # without an ID.\n",
    "    for idx in zeros_idx:\n",
    "        taxIDs.insert(idx, \"1\")\n",
    "\n",
    "    print(\"Look up for Tax IDs complete. Time: %f\" % (end - start))\n",
    "\n",
    "    # Group taxIDs into blocks and submit each block as a query to the web API.\n",
    "    taxid_blocksize = 20\n",
    "    taxid_blocks = [\n",
    "        taxIDs[x : x + taxid_blocksize]\n",
    "        for x in range(0, len(taxIDs), taxid_blocksize)\n",
    "    ]\n",
    "\n",
    "    # Collect records with lineage information\n",
    "    print(\"Collecting taxonomy information...\")\n",
    "    start = time.time()\n",
    "    records = list()\n",
    "    for i, taxid_block in enumerate(taxid_blocks):\n",
    "        handle = Entrez.efetch(db=\"taxonomy\", id=taxid_block, retmode=\"xml\")\n",
    "        recordList = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        for j, record in enumerate(recordList):\n",
    "            if record[\"Lineage\"]:\n",
    "                records.append(record)\n",
    "            else:\n",
    "                taxon = {}\n",
    "                taxon[\"Lineage\"] = \"unknown\"\n",
    "                taxon[\"ScientificName\"] = \"unknown\"\n",
    "                records.append(taxon)\n",
    "    end = time.time()\n",
    "    print(\n",
    "        \"Look up for taxonomy information complete. Time: %f\" % (end - start)\n",
    "    )\n",
    "\n",
    "    [hd, seqs] = readAlg(alg_in)\n",
    "    if len(records) != len(seqs):\n",
    "        sys.exit(\n",
    "            \"ERROR: number of records found do not match the number of \"\n",
    "            \"aligned sequences.\"\n",
    "        )\n",
    "\n",
    "    # Write to the output FASTA file.\n",
    "    if os.path.dirname(alg_out):\n",
    "        Path(os.path.dirname(alg_out)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(alg_out, \"w\") as f:\n",
    "        for i, seq in enumerate(seqs):\n",
    "            hdnew = (\n",
    "                hd[i]\n",
    "                + delimiter\n",
    "                + records[i][\"ScientificName\"]\n",
    "                + delimiter\n",
    "                + \",\".join(records[i][\"Lineage\"].split(\";\"))\n",
    "            )\n",
    "            if records[i][\"Lineage\"] == \"unknown\":\n",
    "                print(\"Unable to add taxonomy information for seq: %s\" % hd[i])\n",
    "            f.write(\">%s\\n\" % hdnew)\n",
    "            f.write(\"%s\\n\" % seq)\n",
    "\n",
    "\n",
    "def clean_al(alg, code=\"ACDEFGHIKLMNPQRSTVWY\", gap=\"-\"):\n",
    "    \"\"\"\n",
    "    Replaces any character that is not a valid amino acid by a gap.\n",
    "\n",
    "    **Arguments** amino acid sequence alignment\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      :code: list of valid amino acid characters (case sensitive)\n",
    "      :gap:  gap character for replacement\n",
    "    \"\"\"\n",
    "\n",
    "    alg_clean = list()\n",
    "    for seq in alg:\n",
    "        seq_clean = \"\"\n",
    "        for aa in seq:\n",
    "            if code.find(aa) != -1:\n",
    "                seq_clean += aa\n",
    "            else:\n",
    "                seq_clean += gap\n",
    "        alg_clean.append(seq_clean)\n",
    "    return alg_clean\n",
    "\n",
    "\n",
    "def MSAsearch(hd, algn, seq, species=None):\n",
    "    \"\"\"\n",
    "    Identify the sequence in the alignment that most closely corresponds to the\n",
    "    species of the reference sequence, and return its index.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      - sequence alignment headers\n",
    "      - alignment sequences\n",
    "      - selected reference sequence (often from a PDB file)\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      :species: species of the reference sequence (Used to speed up alignment\n",
    "                searching when possible)\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      strseqnum = MSASearch(hd, alg0, pdbseq, 'Homo sapiens')\n",
    "    \"\"\"\n",
    "\n",
    "    if species is not None:\n",
    "        species = species.lower()\n",
    "        key_list = list()\n",
    "        for (i, h) in enumerate(hd):\n",
    "            if species in h.lower():\n",
    "                key_list.append(i)\n",
    "        hd = [hd[k] for k in key_list]\n",
    "        algn = [algn[k] for k in key_list]\n",
    "\n",
    "    try:\n",
    "        print(\"Trying MSASearch with ggsearch\")\n",
    "        output_handle = open(\"tmp_pdb_seq.fasta\", \"w\")\n",
    "        SeqIO.write(\n",
    "            SeqRecord(Seq(seq), id=\"PDB sequence\"), output_handle, \"fasta\"\n",
    "        )\n",
    "        output_handle.close()\n",
    "        f = open(\"tmp_algn_seq.fasta\", \"w\")\n",
    "        for i, algn_i in enumerate(algn):\n",
    "            f.write(\">\" + hd[i] + \"\\n\")\n",
    "            f.write(algn_i + \"\\n\")\n",
    "        f.close()\n",
    "        args = [\n",
    "            \"ggsearch36\",\n",
    "            \"-M 1-\" + str(len(algn[0])),\n",
    "            \"-b\",\n",
    "            \"1\",\n",
    "            \"-m 8\",\n",
    "            \"tmp_pdb_seq.fasta\",\n",
    "            \"tmp_algn_seq.fasta\",\n",
    "        ]\n",
    "        output = subprocess.check_output(args)\n",
    "        i_0 = [\n",
    "            i\n",
    "            for i in range(len(hd))\n",
    "            if output.decode(\"ASCII\").split(\"\\t\")[1] in hd[i]\n",
    "        ]\n",
    "        if species is not None:\n",
    "            strseqnum = key_list[i_0[0]]\n",
    "        else:\n",
    "            strseqnum = i_0[0]\n",
    "        os.remove(\"tmp_pdb_seq.fasta\")\n",
    "        os.remove(\"tmp_algn_seq.fasta\")\n",
    "        return strseqnum\n",
    "    except BaseException as e:\n",
    "        print(\"Error: \" + str(e))\n",
    "        try:\n",
    "            from Bio.Emboss.Applications import NeedleCommandline\n",
    "\n",
    "            print(\"Trying MSASearch with EMBOSS\")\n",
    "            output_handle = open(\"tmp_pdb_seq.fasta\", \"w\")\n",
    "            SeqIO.write(\n",
    "                SeqRecord(Seq(seq), id=\"PDB sequence\"), output_handle, \"fasta\"\n",
    "            )\n",
    "            output_handle.close()\n",
    "            output_handle = open(\"tmp_algn_seq.fasta\", \"w\")\n",
    "            s_records = list()\n",
    "            for k, algn_k in enumerate(algn):\n",
    "                s_records.append(\n",
    "                    SeqRecord(Seq(algn_k), id=str(k), description=hd[k])\n",
    "                )\n",
    "            SeqIO.write(s_records, output_handle, \"fasta\")\n",
    "            output_handle.close()\n",
    "            needle_cline = NeedleCommandline(\n",
    "                \"needle\",\n",
    "                asequence=\"tmp_pdb_seq.fasta\",\n",
    "                bsequence=\"tmp_algn_seq.fasta\",\n",
    "                gapopen=10,\n",
    "                gapextend=0.5,\n",
    "                outfile=\"tmp_needle_seq.fasta\",\n",
    "            )\n",
    "            stdout, stderr = needle_cline()\n",
    "            print(stdout + stderr)\n",
    "            algres = open(\"tmp_needle_seq.fasta\", \"r\").readlines()\n",
    "            score = list()\n",
    "            for k in algres:\n",
    "                if k.find(\"Identity: \") > 0:\n",
    "                    score.append(int(k.split()[2].split(\"/\")[0]))\n",
    "            i_0 = score.index(max(score))\n",
    "            if species is not None:\n",
    "                strseqnum = key_list[i_0]\n",
    "            else:\n",
    "                strseqnum = i_0\n",
    "            os.remove(\"tmp_pdb_seq.fasta\")\n",
    "            os.remove(\"tmp_algn_seq.fasta\")\n",
    "            os.remove(\"tmp_neelde_seq.fasta\")\n",
    "            return strseqnum\n",
    "        except BaseException as e:\n",
    "            print(\"Error: \" + str(e))\n",
    "            print(\"Trying MSASearch with BioPython\")\n",
    "            score = list()\n",
    "            for k, s in enumerate(algn):\n",
    "                score.append(\n",
    "                    pairwise2.align.globalxx(\n",
    "                        algn, s, one_alignment_only=1, score_only=1\n",
    "                    )\n",
    "                )\n",
    "            i_0 = score.index(max(score))\n",
    "            if species is not None:\n",
    "                strseqnum = key_list[i_0]\n",
    "            else:\n",
    "                strseqnum = i_0\n",
    "            print(\"BP strseqnum is %i\" % (strseqnum))\n",
    "            return strseqnum\n",
    "\n",
    "\n",
    "def chooseRefSeq(alg):\n",
    "    \"\"\"\n",
    "    This function chooses a default reference sequence if none is given by\n",
    "    taking the sequence which has the mean pairwise sequence identity closest\n",
    "    to that of the entire alignment.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      i_ref = chooseRefSeq(msa_num)\n",
    "    \"\"\"\n",
    "\n",
    "    if len(alg) > 1000:\n",
    "        seqw = seqWeights(alg)\n",
    "        keep_seq = randSel(seqw, 1000)\n",
    "    else:\n",
    "        keep_seq = [k for k in range(len(alg))]\n",
    "    algNew = [alg[k] for k in keep_seq]\n",
    "    numAlgNew = lett2num(algNew)\n",
    "    simMat = seqSim(numAlgNew)\n",
    "    listS = [\n",
    "        simMat[i, j]\n",
    "        for i in range(simMat.shape[0])\n",
    "        for j in range(i + 1, simMat.shape[1])\n",
    "    ]\n",
    "    meanSID = list()\n",
    "    for k in range(len(simMat)):\n",
    "        meanSID.append(simMat[k].mean())\n",
    "    meanDiff = abs(meanSID - np.mean(listS))\n",
    "    strseqnum = [i for i, k in enumerate(meanDiff) if k == min(meanDiff)]\n",
    "    return strseqnum[0]\n",
    "\n",
    "\n",
    "def makeATS(sequences, refpos, refseq, iref=0, truncate=False):\n",
    "    \"\"\"\n",
    "    If specified, truncate the alignment to the structure (assumes MSAsearch\n",
    "    has already been run to identify the reference sequence (iref)) and produce\n",
    "    a mapping (ats) between alignment positions and the positions in the\n",
    "    reference sequence (refpos).\n",
    "\n",
    "    .. _MSAsearch: scaTools.html#scaTools.MSAsearch\n",
    "\n",
    "     **Arguments**\n",
    "\n",
    "       - sequences\n",
    "       - reference positions\n",
    "       - reference sequence\n",
    "       - iref, the index of the sequence in the alignment with the highest\n",
    "         identity to the reference\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "       :truncate: (bool) truncate the alignment to positions that align to the\n",
    "                  reference sequence\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      sequences_trun, ats_new = sca.makeATS(sequences_full, ats_pdb, seq_pdb, i_ref)\n",
    "    \"\"\"\n",
    "\n",
    "    if truncate:\n",
    "        print(\"truncating to reference sequence...\")\n",
    "\n",
    "        # Removing gaps:\n",
    "        pos_ref = [i for i, a in enumerate(refseq) if a != \"-\"]\n",
    "        seq_ref = \"\".join([refseq[i] for i in pos_ref])\n",
    "        ats_ref = [refpos[i] for i in pos_ref]\n",
    "        pos_alg = [i for i, a in enumerate(sequences[iref]) if a != \"-\"]\n",
    "        seq_tr = [\"\".join([sq[i] for i in pos_alg]) for sq in sequences]\n",
    "\n",
    "        # Positions to keep in the alignment and pbd sequences\n",
    "        # (no gap in any of them after co-alignment):\n",
    "        seqal_ref, seqal_alg, _, _, _ = pairwise2.align.globalms(\n",
    "            seq_ref, seq_tr[iref], 2, -1, -0.5, -0.1\n",
    "        )[0]\n",
    "        keep_ref, keep_alg = list(), list()\n",
    "        j_ref, j_alg = 0, 0\n",
    "        for i, seqal_ref_i in enumerate(seqal_ref):\n",
    "            if seqal_ref_i != \"-\" and seqal_alg[i] != \"-\":\n",
    "                keep_ref.append(j_ref)\n",
    "                keep_alg.append(j_alg)\n",
    "            if seqal_ref_i != \"-\":\n",
    "                j_ref += 1\n",
    "            if seqal_alg[i] != \"-\":\n",
    "                j_alg += 1\n",
    "        sequences_out = [\"\".join([sq[i] for i in keep_alg]) for sq in seq_tr]\n",
    "        ats_out = [ats_ref[i] for i in keep_ref]\n",
    "    else:\n",
    "        tmp = sequences[iref].replace(\"-\", \".\")\n",
    "        refseq = refseq.replace(\"-\", \"\")\n",
    "        seqal_ref, seqal_alg, _, _, _ = pairwise2.align.globalms(\n",
    "            refseq, tmp, 2, -1, -0.5, -0.1\n",
    "        )[0]\n",
    "        print(\n",
    "            \"len refseq %i, len refpos %i, len algseq %i, \"\n",
    "            \"len pairalg %i, len gloalg %i\"\n",
    "            % (\n",
    "                len(refseq),\n",
    "                len(refpos),\n",
    "                len(tmp),\n",
    "                len(seqal_alg),\n",
    "                len(sequences[0]),\n",
    "            )\n",
    "        )\n",
    "        ats_out = list()\n",
    "        j_ref = 0\n",
    "        j_pdb = 0\n",
    "        for i, seqal_alg_i in enumerate(seqal_alg):\n",
    "            if seqal_alg_i == \".\" and seqal_ref[i] == \"-\":\n",
    "                ats_out.insert(j_ref, \"-\")\n",
    "                j_ref += 1\n",
    "            elif seqal_alg_i != \".\" and seqal_alg_i != \"-\":\n",
    "                if seqal_ref[i] != \"-\":\n",
    "                    ats_out.insert(j_ref, refpos[j_pdb])\n",
    "                    j_ref += 1\n",
    "                    j_pdb += 1\n",
    "                else:\n",
    "                    ats_out.insert(j_ref, \"-\")\n",
    "                    j_ref += 1\n",
    "            elif seqal_alg_i == \".\" and seqal_ref[i] != \"-\":\n",
    "                ats_out.insert(j_ref, refpos[j_pdb])\n",
    "                j_ref += 1\n",
    "                j_pdb += 1\n",
    "            elif seqal_alg_i == \"-\":\n",
    "                j_pdb += 1\n",
    "        sequences_out = sequences\n",
    "    return sequences_out, ats_out\n",
    "\n",
    "\n",
    "def lett2num(msa_lett, code=\"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "    \"\"\"\n",
    "    Translate an alignment from a representation where the 20 natural amino\n",
    "    acids are represented by letters to a representation where they are\n",
    "    represented by the numbers 1,...,20, with any symbol not corresponding to\n",
    "    an amino acid represented by 0.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "       msa_num = lett2num(msa_lett, code='ACDEFGHIKLMNPQRSTVWY')\n",
    "    \"\"\"\n",
    "\n",
    "    lett2index = {aa: i + 1 for i, aa in enumerate(code)}\n",
    "    [Nseq, Npos] = [len(msa_lett), len(msa_lett[0])]\n",
    "    msa_num = np.zeros((Nseq, Npos)).astype(int)\n",
    "    for s, seq in enumerate(msa_lett):\n",
    "        for i, lett in enumerate(seq):\n",
    "            if lett in code:\n",
    "                msa_num[s, i] = lett2index[lett]\n",
    "    return msa_num\n",
    "\n",
    "\n",
    "def alg2bin(alg, N_aa=20):\n",
    "    \"\"\"\n",
    "    Translate an alignment of matrix of size M sequences by L positions where\n",
    "    the amino acids are represented by numbers between 0 and N_aa (obtained\n",
    "    using lett2num) to a binary array of size M x (N_aa x L).\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Abin = alg2bin(alg, N_aa=20)\n",
    "    \"\"\"\n",
    "\n",
    "    [N_seq, N_pos] = alg.shape\n",
    "    Abin_tensor = np.zeros((N_aa, N_pos, N_seq))\n",
    "    for ia in range(N_aa):\n",
    "        Abin_tensor[ia, :, :] = (alg == ia + 1).T\n",
    "    Abin = Abin_tensor.reshape(N_aa * N_pos, N_seq, order=\"F\").T\n",
    "    return Abin\n",
    "\n",
    "\n",
    "def alg2binss(alg, N_aa=20):\n",
    "    \"\"\"\n",
    "    Translate an alignment of matrix of size M sequences by L positions where\n",
    "    the amino acids are represented by numbers between 0 and N_aa (obtained\n",
    "    using lett2num) to a sparse binary array of size M x (N_aa x L).\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Abin = alg2binss(alg, N_aa=20)\n",
    "    \"\"\"\n",
    "\n",
    "    [N_seq, N_pos] = alg.shape\n",
    "    Abin_tensor = np.zeros((N_aa, N_pos, N_seq))\n",
    "    for ia in range(N_aa):\n",
    "        Abin_tensor[ia, :, :] = (alg == ia + 1).T\n",
    "    Abin = sparsify(Abin_tensor.reshape(N_aa * N_pos, N_seq, order=\"F\").T)\n",
    "    return Abin\n",
    "\n",
    "\n",
    "def seqWeights(alg, max_seqid=0.8, gaps=1):\n",
    "    \"\"\"\n",
    "    Compute sequence weights for an alignment (format: list of sequences) where\n",
    "    the weight of a sequence is the inverse of the number of sequences in its\n",
    "    neighborhood, defined as the sequences with sequence similarity below\n",
    "    max_seqid. The sum of the weights defines an effective number of sequences.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      :alg: list of sequences\n",
    "\n",
    "    **Keyword Arguments**\n",
    "\n",
    "      :max_seqid:\n",
    "      :gaps: If gaps == 1 (default), considering gaps as a 21st amino acid, if\n",
    "             gaps == 0, not considering them.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      seqw = seqWeights(alg)\n",
    "    \"\"\"\n",
    "\n",
    "    codeaa = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    if gaps == 1:\n",
    "        codeaa += \"-\"\n",
    "    msa_num = lett2num(alg, code=codeaa)\n",
    "    Nseq, Npos = msa_num.shape\n",
    "    X2d = alg2bin(msa_num, N_aa=len(codeaa))\n",
    "    simMat = X2d.dot(X2d.T) / Npos\n",
    "    seqw = np.array(1 / (simMat > max_seqid).sum(axis=0))\n",
    "    seqw.shape = (1, Nseq)\n",
    "    return seqw\n",
    "\n",
    "\n",
    "def filterSeq(alg0, sref=0.5, max_fracgaps=0.2, min_seqid=0.2, max_seqid=0.8):\n",
    "    \"\"\"\n",
    "    Take in an alignment (alg0, assumed to be filtered to remove highly gapped\n",
    "    positions), a reference sequence, the maximum fraction of gaps allowed per\n",
    "    sequence (max_fracgaps), the minimum and maximum sequence identities to the\n",
    "    reference sequence (min_seqid and max_seqid), and return (1) alg, the\n",
    "    alignment filtered to remove sequences with more than max_fracgaps (i.e.\n",
    "    partial seqs), (2) seqw, a vector of weights for each sequence, (3)\n",
    "    seqkeep, the indices of the original alignment (alg0) retained in alg:\n",
    "\n",
    "    **Note:** if sref is set to 0.5, filterSeq calls chooseRefSeq_ to\n",
    "    automatically select a reference sequence.\n",
    "\n",
    "    .. _chooseRefSeq: scaTools.html#scaTools.chooseRefSeq\n",
    "\n",
    "    **Example:**\n",
    "\n",
    "        alg, seqw, seqkeep = filterSeq(alg0, iref, max_fracgaps=.2, min_seqid=.2, max_seqid=.8)\n",
    "    \"\"\"\n",
    "\n",
    "    if sref == 0.5:\n",
    "        sref = chooseRefSeq(alg0)\n",
    "    Nseq, Npos = len(alg0), len(alg0[0])\n",
    "    # Elimination of sequences with too many gaps:\n",
    "    seqkeep0 = [\n",
    "        s for s in range(Nseq) if alg0[s].count(\"-\") / Npos < max_fracgaps\n",
    "    ]\n",
    "    print(\n",
    "        \"Keeping %i sequences of %i sequences (after filtering for gaps)\"\n",
    "        % (len(seqkeep0), Nseq)\n",
    "    )\n",
    "    # Elimination of sequences too dissimilar to the reference (trimming):\n",
    "    seqkeep = [\n",
    "        s\n",
    "        for s in seqkeep0\n",
    "        if sum([alg0[s][i] == alg0[sref][i] for i in range(Npos)]) / Npos\n",
    "        > min_seqid\n",
    "    ]\n",
    "    print(\n",
    "        \"Keeping %i sequences of %i sequences \"\n",
    "        \"(after filtering for seq similarity)\" % (len(seqkeep), len(seqkeep0))\n",
    "    )\n",
    "    alg = [alg0[s] for s in seqkeep]\n",
    "    # Sequence weights (smoothing, here effectively treats gaps as a 21st amino\n",
    "    # acid):\n",
    "    seqw = seqWeights(alg, max_seqid)\n",
    "    return alg, seqw, seqkeep\n",
    "\n",
    "\n",
    "def filterPos(alg, seqw=[1], max_fracgaps=0.2):\n",
    "    \"\"\"\n",
    "    Truncate the positions of an input alignment to reduce gaps, taking into\n",
    "    account sequence weights.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      :alg: An MxL list of sequences\n",
    "\n",
    "    **Keyword Arguments**\n",
    "      :seqw: vector of sequence weights (default is uniform weights)\n",
    "      :max_fracgaps: maximum fraction of gaps allowed at a position\n",
    "\n",
    "    **Returns:**\n",
    "      :alg_tr: the truncated alignment\n",
    "      :selpos: the index of retained positions (indices start at 0 for the\n",
    "               first position)\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "       alg_tr, selpos = filterPos(alg, seqw, max_fracgaps=.2)\n",
    "    \"\"\"\n",
    "\n",
    "    Nseq, Npos = len(alg), len(alg[0])\n",
    "    if len(seqw) == 1:\n",
    "        seqw = np.tile(1, (1, Nseq))\n",
    "\n",
    "    # Fraction of gaps, taking into account sequence weights:\n",
    "    gapsMat = np.array(\n",
    "        [[int(alg[s][i] == \"-\") for i in range(Npos)] for s in range(Nseq)]\n",
    "    )\n",
    "    seqwn = seqw / seqw.sum()\n",
    "    gapsperpos = seqwn.dot(gapsMat)[0]\n",
    "\n",
    "    # Selected positions:\n",
    "    selpos = [i for i in range(Npos) if gapsperpos[i] < max_fracgaps]\n",
    "\n",
    "    # Truncation:\n",
    "    alg_tr = [\"\".join([alg[s][i] for i in selpos]) for s in range(Nseq)]\n",
    "    return alg_tr, selpos\n",
    "\n",
    "\n",
    "def randSel(seqw, Mtot, keepSeq=[]):\n",
    "    \"\"\"\n",
    "    Random selection of Mtot sequences, drawn with weights and without\n",
    "    replacement. The seed for the random number generator is fixed to ensure\n",
    "    reproducibility.\n",
    "\n",
    "    **Arguments**\n",
    "        - `seqw` = the sequence weights\n",
    "        - `Mtot` = the total number of sequences for selection\n",
    "\n",
    "    **Keyword Arguments**\n",
    "        - `keepSeq` = an (optional) list of sequnces to keep. This can be\n",
    "          useful if you would like to retain the reference sequence for\n",
    "          example.\n",
    "\n",
    "    **Example**::\n",
    "      selection = randSel(seqw, Mtot, [iref])\n",
    "    \"\"\"\n",
    "\n",
    "    rand.seed(0)  # sets the RNG from the 'random' module, not 'numpy.random'\n",
    "    return weighted_rand_list(seqw[0], Mtot, keepSeq)\n",
    "\n",
    "\n",
    "def weighted_rand_list(weights, Nmax, keepList):\n",
    "    \"\"\"\n",
    "    Generate a random list of at most Nmax elements with weights (numpy array)\n",
    "    but without replacement. Called by randSel_.\n",
    "\n",
    "    .. _randSel: scaTools.html#scaTools.randSel\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      selection = weighted_rand_list(weights, Nmax, [iref])\n",
    "    \"\"\"\n",
    "\n",
    "    Ntot = min((weights > 0).sum(), Nmax)\n",
    "    wlist = [w for w in weights]\n",
    "    selection = list()\n",
    "    for k in keepList:\n",
    "        selection.append(k)\n",
    "        wlist[k] = 0\n",
    "        Ntot -= 1\n",
    "    for k in range(Ntot):\n",
    "        i = weighted_rand_sel(wlist)\n",
    "        selection.append(i)\n",
    "        wlist[i] = 0\n",
    "    return selection\n",
    "\n",
    "\n",
    "def weighted_rand_sel(weights):\n",
    "    \"\"\"\n",
    "    Generate a random index with probability given by input weights. Called by\n",
    "    weighted_rand_list_.\n",
    "\n",
    "    .. _weighted_rand_list: scaTools.html#scaTools.weighted_rand_list\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      index = weighted_rand_sel(weights)\n",
    "    \"\"\"\n",
    "\n",
    "    rnd = rand.random() * sum(weights)\n",
    "    for i, w in enumerate(weights):\n",
    "        rnd -= w\n",
    "        if rnd < 0:\n",
    "            return i\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# BASIC STATISTICAL FUNCTIONS\n",
    "\n",
    "\n",
    "def freq(alg, seqw=1, Naa=20, lbda=0, freq0=np.ones(20) / 21):\n",
    "    \"\"\"\n",
    "    Compute amino acid frequencies for a given alignment.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      :alg: a MxL sequence alignment (converted using lett2num_)\n",
    "\n",
    "    .. _lett2num: scaTools.html#scaTools.lett2num\n",
    "\n",
    "    **Keyword Arguments**\n",
    "      :seqw:  a vector of sequence weights (1xM)\n",
    "      :Naa:   the number of amino acids\n",
    "      :lbda:  lambda parameter for setting the frequency of pseudo-counts (0\n",
    "              for no pseudo counts)\n",
    "      :freq0: expected average frequency of amino acids at all positions\n",
    "\n",
    "    **Returns**\n",
    "\n",
    "      :freq1: the frequencies of amino acids at each position taken\n",
    "              independently (Naa*L)\n",
    "      :freq2: the joint frequencies of amino acids at pairs of positions\n",
    "              (freq2, Naa*L * Naa*L)\n",
    "      :freq0: the average frequency of amino acids at all positions (Naa)\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      freq1, freq2, freq0 = freq(alg, seqw, lbda=lbda)\n",
    "    \"\"\"\n",
    "\n",
    "    Nseq, Npos = alg.shape\n",
    "    if isinstance(seqw, int) and seqw == 1:\n",
    "        seqw = np.ones((1, Nseq))\n",
    "    seqwn = seqw / seqw.sum()\n",
    "    al2d = alg2binss(alg, Naa)\n",
    "    freq1 = seqwn.dot(np.array(al2d.todense()))[0]\n",
    "    freq2 = np.array(\n",
    "        al2d.T.dot(scipy.sparse.diags(seqwn[0], 0)).dot(al2d).todense()\n",
    "    )\n",
    "    # Background:\n",
    "    block = np.outer(freq0, freq0)\n",
    "    freq2_bkg = np.tile(block, (Npos, Npos))\n",
    "    for i in range(Npos):\n",
    "        freq2_bkg[Naa * i : Naa * (i + 1), Naa * i : Naa * (i + 1)] = np.diag(\n",
    "            freq0\n",
    "        )\n",
    "    # Regularizations:\n",
    "    freq1_reg = (1 - lbda) * freq1 + lbda * np.tile(freq0, Npos)\n",
    "    freq2_reg = (1 - lbda) * freq2 + lbda * freq2_bkg\n",
    "    freq0_reg = freq1_reg.reshape(Npos, Naa).mean(axis=0)\n",
    "    return freq1_reg, freq2_reg, freq0_reg\n",
    "\n",
    "\n",
    "def eigenVect(M):\n",
    "    \"\"\"\n",
    "    Return the eigenvectors and eigenvalues, ordered by decreasing values of\n",
    "    the eigenvalues, for a real symmetric matrix M. The sign of the\n",
    "    eigenvectors is fixed so that the mean of its components is non-negative.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "       eigenVectors, eigenValues = eigenVect(M)\n",
    "    \"\"\"\n",
    "\n",
    "    eigenValues, eigenVectors = np.linalg.eigh(M)\n",
    "    idx = (-eigenValues).argsort()\n",
    "    eigenValues = eigenValues[idx]\n",
    "    eigenVectors = eigenVectors[:, idx]\n",
    "    for k in range(eigenVectors.shape[1]):\n",
    "        if np.sign(np.mean(eigenVectors[:, k])) != 0:\n",
    "            eigenVectors[:, k] = (\n",
    "                np.sign(np.mean(eigenVectors[:, k])) * eigenVectors[:, k]\n",
    "            )\n",
    "    return eigenVectors, eigenValues\n",
    "\n",
    "\n",
    "def svdss(X, k=6):\n",
    "    \"\"\"\n",
    "    Singular value decomposition for sparse matrices (top k components). The\n",
    "    singular values are ordered by decreasing values, the sign of the singular\n",
    "    vectors is fixed, and the convention is that X = u.dot(s).dot(v.T):\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      u, s ,v = svdss(X, k=6)\n",
    "    \"\"\"\n",
    "\n",
    "    u, s, vt = scipy.sparse.linalg.svds(X, k)\n",
    "    idx = (-s).argsort()\n",
    "    s = s[idx]\n",
    "    u = u[:, idx]\n",
    "    for j in range(u.shape[1]):\n",
    "        sign = np.sign(np.mean(u[:, j]))\n",
    "        u[:, j] = sign * u[:, j]\n",
    "    v = X.T.dot(u).dot(np.diag(1 / s))\n",
    "    return u, s, v\n",
    "\n",
    "\n",
    "def basicICA(x, r0, Niter, tolerance=1e-15):\n",
    "    \"\"\"\n",
    "    Basic ICA algorithm, based on work by Bell & Sejnowski (infomax). The input\n",
    "    data should preferentially be sphered, i.e., x.T.dot(x) = 1\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      :x: LxM input matrix where L = # features and M = # samples\n",
    "      :r: learning rate / relaxation parameter (e.g. r=.0001)\n",
    "      :Niter: number of iterations (e.g. 1000)\n",
    "\n",
    "    **Returns**\n",
    "\n",
    "      :w: unmixing matrix\n",
    "      :change: record of incremental changes during the iterations.\n",
    "\n",
    "    **Note** r and Niter should be adjusted to achieve convergence, which\n",
    "    should be assessed by visualizing 'change' with plot(range(iter), change)\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      [w, change] = basicICA(x, r, Niter)\n",
    "    \"\"\"\n",
    "\n",
    "    [L, M] = x.shape\n",
    "    w = np.eye(L)\n",
    "    change = list()\n",
    "    r = r0 / M\n",
    "    with np.errstate(over=\"raise\"):\n",
    "        try:\n",
    "            for _ in range(Niter):\n",
    "                w_old = np.copy(w)\n",
    "                u = w.dot(x)\n",
    "                w += r * (\n",
    "                    M * np.eye(L) + (1.0 - 2.0 / (1.0 + np.exp(-u))).dot(u.T)\n",
    "                ).dot(w)\n",
    "                delta = (w - w_old).ravel()\n",
    "                val = delta.dot(delta.T)\n",
    "                change.append(val)\n",
    "                if np.isclose(val, 0, atol=tolerance):\n",
    "                    break\n",
    "                if _ == Niter - 1:\n",
    "                    print(\"basicICA failed to converge: \" + str(val))\n",
    "        except FloatingPointError as e:\n",
    "            sys.exit(\"Error: basicICA \" + str(e))\n",
    "    return [w, change]\n",
    "\n",
    "\n",
    "def rotICA(V, kmax=6, learnrate=0.1, iterations=100000):\n",
    "    \"\"\"\n",
    "    ICA rotation (using basicICA) with default parameters and normalization of\n",
    "    outputs.\n",
    "\n",
    "    **Example**::\n",
    "       Vica, W = rotICA(V, kmax=6, learnrate=.0001, iterations=10000)\n",
    "    \"\"\"\n",
    "\n",
    "    V1 = V[:, :kmax].T\n",
    "    [W, changes] = basicICA(V1, learnrate, iterations)\n",
    "    Vica = (W.dot(V1)).T\n",
    "    for n in range(kmax):\n",
    "        imax = abs(Vica[:, n]).argmax()\n",
    "        Vica[:, n] = (\n",
    "            np.sign(Vica[imax, n]) * Vica[:, n] / np.linalg.norm(Vica[:, n])\n",
    "        )\n",
    "    return Vica, W\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# SCA FUNCTIONS\n",
    "\n",
    "\n",
    "def seqSim(alg):\n",
    "    \"\"\"\n",
    "    Take an MxL alignment (converted to numeric representation using lett2num_)\n",
    "    and compute a MxM matrix of sequence similarities.\n",
    "\n",
    "    **Example**::\n",
    "      simMat = seqSim(alg)\n",
    "\n",
    "    \"\"\"\n",
    "    # Get the number of sequences and number of positions:\n",
    "    [Nseq, Npos] = alg.shape\n",
    "    # Convert into a M*(20L) (sparse) binary array:\n",
    "    X2d = alg2bin(alg)\n",
    "    simMat = X2d.dot(X2d.T) / Npos\n",
    "    return simMat\n",
    "\n",
    "\n",
    "def posWeights(\n",
    "    alg,\n",
    "    seqw=1,\n",
    "    lbda=0,\n",
    "    N_aa=20,\n",
    "    freq0=np.array(\n",
    "        [\n",
    "            0.073,\n",
    "            0.025,\n",
    "            0.050,\n",
    "            0.061,\n",
    "            0.042,\n",
    "            0.072,\n",
    "            0.023,\n",
    "            0.053,\n",
    "            0.064,\n",
    "            0.089,\n",
    "            0.023,\n",
    "            0.043,\n",
    "            0.052,\n",
    "            0.040,\n",
    "            0.052,\n",
    "            0.073,\n",
    "            0.056,\n",
    "            0.063,\n",
    "            0.013,\n",
    "            0.033,\n",
    "        ]\n",
    "    ),\n",
    "    tolerance=1e-12,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute single-site measures of conservation, and the sca position weights,\n",
    "    :math:`\\\\frac {\\partial {D_i^a}}{\\partial {f_i^a}}`\n",
    "\n",
    "    **Arguments**\n",
    "         - `alg` =  MSA, dimensions MxL, converted to numerical representation\n",
    "           with lett2num_\n",
    "         - `seqw` = a vector of M sequence weights (default is uniform\n",
    "           weighting)\n",
    "         - `lbda` = pseudo-counting frequencies, default is no pseudocounts\n",
    "         - `freq0` =  background amino acid frequencies :math:`q_i^a`\n",
    "\n",
    "    **Returns:**\n",
    "         - `Wia` = positional weights from the derivation of a relative\n",
    "           entropy, :math:`\\\\frac {\\partial {D_i^a}}{\\partial {f_i^a}}` (Lx20)\n",
    "         - `Dia` = the relative entropy per position and amino acid (Lx20)\n",
    "         - `Di` = the relative entropy per position (L)\n",
    "\n",
    "    **Example**::\n",
    "       Wia, Dia, Di = posWeights(alg, seqw=1,freq0)\n",
    "    \"\"\"\n",
    "\n",
    "    N_seq, N_pos = alg.shape\n",
    "    if isinstance(seqw, int) and seqw == 1:\n",
    "        seqw = np.ones((1, N_seq))\n",
    "    freq1, freq2, _ = freq(alg, Naa=N_aa, seqw=seqw, lbda=lbda, freq0=freq0)\n",
    "    # Overall fraction of gaps:\n",
    "    theta = 1 - freq1.sum() / N_pos\n",
    "    if theta < tolerance:\n",
    "        theta = 0\n",
    "    # Background frequencies with gaps:\n",
    "    freqg0 = (1 - theta) * freq0\n",
    "    freq0v = np.tile(freq0, N_pos)\n",
    "    iok = [i for i in range(N_pos * N_aa) if (freq1[i] > 0 and freq1[i] < 1)]\n",
    "    # Derivatives of relative entropy per position and amino acid:\n",
    "    Wia = np.zeros(N_pos * N_aa)\n",
    "    Wia[iok] = abs(\n",
    "        np.log(\n",
    "            (freq1[iok] * (1 - freq0v[iok])) / ((1 - freq1[iok]) * freq0v[iok])\n",
    "        )\n",
    "    )\n",
    "    # Relative entropies per position and amino acid:\n",
    "    Dia = np.zeros(N_pos * N_aa)\n",
    "    Dia[iok] = freq1[iok] * np.log(freq1[iok] / freq0v[iok]) + (\n",
    "        1 - freq1[iok]\n",
    "    ) * np.log((1 - freq1[iok]) / (1 - freq0v[iok]))\n",
    "    # Overall relative entropies per positions (taking gaps into account):\n",
    "    Di = np.zeros(N_pos)\n",
    "    for i in range(N_pos):\n",
    "        freq1i = freq1[N_aa * i : N_aa * (i + 1)]\n",
    "        aok = [a for a in range(N_aa) if freq1i[a] > 0]\n",
    "        flogf = freq1i[aok] * np.log(freq1i[aok] / freqg0[aok])\n",
    "        Di[i] = flogf.sum()\n",
    "        freqgi = 1 - freq1i.sum()\n",
    "        if freqgi > tolerance:\n",
    "            Di[i] += freqgi * np.log(freqgi / theta)\n",
    "    return Wia, Dia, Di\n",
    "\n",
    "\n",
    "def seqProj(msa_num, seqw, kseq=15, kica=6):\n",
    "    \"\"\"\n",
    "    Compute three different projections of the sequences based on eigenvectors\n",
    "    of the sequence similarity matrix.\n",
    "\n",
    "    **Arguments**\n",
    "       -  `msa_num` = sequence alignment (previously converted to numerical\n",
    "          representation using lett2num_)\n",
    "       -  `seqw` = a vector of sequence weights\n",
    "\n",
    "    **Keyword Arguments**\n",
    "       -  `kseq` = number of eigenvectors to compute\n",
    "       -  `kica` = number of independent components to compute\n",
    "\n",
    "    **Returns:**\n",
    "       -  `Useq[0]/Uica[0]` =  use no weight\n",
    "       -  `Useq[1]/Uica[1]` =  use sequence weights\n",
    "       -  `Useq[2]/Uica[2]` =  use sequence weights and positional weights\n",
    "\n",
    "    **Example:**\n",
    "      Useq, Uica = sca.seqProj(msa_num, seqw, kseq = 30, kica = 15)\n",
    "    \"\"\"\n",
    "\n",
    "    posw, Dia, Di = posWeights(msa_num, seqw)\n",
    "    Useq = list()\n",
    "\n",
    "    # 1 - raw:\n",
    "    X2d = alg2binss(msa_num)\n",
    "    Useq.append(svdss(X2d, k=kseq)[0])\n",
    "\n",
    "    # 2 - with sequence weights:\n",
    "    X2dw = sparsify(np.diag(np.sqrt(seqw[0]))).dot(X2d)\n",
    "    u, s, v = svdss(X2dw, k=kseq)\n",
    "    Useq.append(X2d.dot(v).dot(np.diag(1 / s)))\n",
    "\n",
    "    # 3 - with sequence and position weights:\n",
    "    X2dp = X2d.dot(sparsify(np.diag(posw)))\n",
    "    X2dpw = sparsify(np.diag(np.sqrt(seqw[0]))).dot(X2dp)\n",
    "    u, s, v = svdss(X2dpw, k=kseq)\n",
    "    Useq.append(X2dp.dot(v).dot(np.diag(1 / s)))\n",
    "\n",
    "    # Fixing the sign:\n",
    "    for U in Useq:\n",
    "        for j in range(U.shape[1]):\n",
    "            U[:, j] = np.sign(np.mean(U[:, j])) * U[:, j]\n",
    "\n",
    "    # Rotation by ICA (default is kica=6):\n",
    "    Uica = list()\n",
    "    for U in Useq:\n",
    "        Uica.append(rotICA(U, kmax=kica)[0])\n",
    "    return Useq, Uica\n",
    "\n",
    "\n",
    "def scaMat(alg, seqw=1, norm=\"frob\", lbda=0, freq0=np.ones(20) / 21):\n",
    "    \"\"\"\n",
    "    Computes the SCA matrix.\n",
    "\n",
    "     **Arguments**\n",
    "\n",
    "       :alg: A MxL multiple sequence alignment, converted to numeric\n",
    "             representation with lett2num_\n",
    "\n",
    "     **Keyword Arguments**\n",
    "\n",
    "       :seqw: A vector of sequence weights (default: uniform weights)\n",
    "       :norm: The type of matrix norm used for dimension reduction of the SCA\n",
    "              correlation tensor to a positional correlation matrix.  Use\n",
    "              'spec' for spectral norm and 'frob' for Frobenius norm. The\n",
    "              frobenius norm is the default.\n",
    "       :lbda: lambda parameter for setting the frequency of pseudo-counts (0\n",
    "              for no pseudo counts)\n",
    "       :freq0: background expectation for amino acid frequencies\n",
    "\n",
    "     **Returns**\n",
    "\n",
    "       :Cp: the LxL SCA positional correlation matrix\n",
    "       :tX: the projected MxL alignment\n",
    "       :projMat: the projector\n",
    "\n",
    "     **Example**::\n",
    "\n",
    "       Csca, tX, projMat = scaMat(alg, seqw, norm='frob', lbda=0.03)\n",
    "    \"\"\"\n",
    "\n",
    "    N_seq, N_pos = alg.shape\n",
    "    N_aa = 20\n",
    "    if isinstance(seqw, int) and seqw == 1:\n",
    "        seqw = np.ones((1, N_seq))\n",
    "    freq1, freq2, freq0 = freq(\n",
    "        alg, Naa=N_aa, seqw=seqw, lbda=lbda, freq0=freq0\n",
    "    )\n",
    "    Wpos = posWeights(alg, seqw, lbda)[0]\n",
    "    tildeC = np.outer(Wpos, Wpos) * (freq2 - np.outer(freq1, freq1))\n",
    "\n",
    "    # Positional correlations:\n",
    "    Cspec = np.zeros((N_pos, N_pos))\n",
    "    Cfrob = np.zeros((N_pos, N_pos))\n",
    "    P = np.zeros((N_pos, N_pos, N_aa))\n",
    "    for i in range(N_pos):\n",
    "        for j in range(i, N_pos):\n",
    "            u, s, vt = np.linalg.svd(\n",
    "                tildeC[N_aa * i : N_aa * (i + 1), N_aa * j : N_aa * (j + 1)]\n",
    "            )\n",
    "            Cspec[i, j] = s[0]\n",
    "            Cfrob[i, j] = np.sqrt(sum(s ** 2))\n",
    "            P[i, j, :] = np.sign(np.mean(u[:, 0])) * u[:, 0]\n",
    "            P[j, i, :] = np.sign(np.mean(u[:, 0])) * vt[0, :].T\n",
    "    Cspec += np.triu(Cspec, 1).T\n",
    "    Cfrob += np.triu(Cfrob, 1).T\n",
    "\n",
    "    # Projector:\n",
    "    al2d = np.array(alg2binss(alg).todense())\n",
    "    tX = np.zeros((N_seq, N_pos))\n",
    "    Proj = Wpos * freq1\n",
    "    ProjMat = np.zeros((N_pos, N_aa))\n",
    "    for i in range(N_pos):\n",
    "        Projati = Proj[N_aa * i : N_aa * (i + 1)]\n",
    "        if sum(Projati ** 2) > 0:\n",
    "            Projati /= np.sqrt(sum(Projati ** 2))\n",
    "        ProjMat[i, :] = Projati\n",
    "        tX[:, i] = al2d[:, N_aa * i : N_aa * (i + 1)].dot(Projati.T)\n",
    "    if norm == \"frob\":\n",
    "        Cspec = Cfrob\n",
    "    return Cspec, tX, Proj\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# PROJECTIONS OF ANNOATED SEQUENCES\n",
    "\n",
    "\n",
    "def projUica(msa_ann, msa_num, seqw, kica=6):\n",
    "    \"\"\"\n",
    "    Compute the projection of an alignment (msa_ann) on the kpos ICA components\n",
    "    of the sequence space of another (msa_num, seqw).This is useful to compare\n",
    "    the sequence space of one alignment to another.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Uica_ann, Uica = projUpica(msa_ann, msa_num_ seqw, kica=6)\n",
    "    \"\"\"\n",
    "\n",
    "    X2d = alg2binss(msa_num)\n",
    "    posw, Dia, Di = posWeights(msa_num, seqw)\n",
    "    X2dw = sparsify(np.diag(np.sqrt(seqw[0]))).dot(X2d)\n",
    "    u, s, v = svdss(X2dw, k=kica)\n",
    "    P = v.dot(np.diag(1 / s))\n",
    "    U = X2d.dot(P)\n",
    "    for j in range(U.shape[1]):\n",
    "        P[:, j] = np.sign(np.mean(U[:, j])) * P[:, j]\n",
    "        U[:, j] = np.sign(np.mean(U[:, j])) * U[:, j]\n",
    "    U, W = rotICA(U, kmax=kica)\n",
    "    X2d_new = alg2binss(msa_ann)\n",
    "    U0 = X2d.dot(P)\n",
    "    U1 = X2d_new.dot(P)\n",
    "    Ui0 = (W.dot(U0[:, :kica].T)).T\n",
    "    Ui1 = (W.dot(U1[:, :kica].T)).T\n",
    "    for n in range(kica):\n",
    "        imax = abs(Ui0[:, n]).argmax()\n",
    "        Ui1[:, n] = (\n",
    "            np.sign(Ui0[imax, n]) * Ui1[:, n] / np.linalg.norm(Ui0[:, n])\n",
    "        )\n",
    "        Ui0[:, n] = (\n",
    "            np.sign(Ui0[imax, n]) * Ui0[:, n] / np.linalg.norm(Ui0[:, n])\n",
    "        )\n",
    "    return Ui1, Ui0\n",
    "\n",
    "\n",
    "def projAlg(alg, Proj):\n",
    "    \"\"\"\n",
    "    Projection of an alignment (alg) based on a projector (Proj). The input\n",
    "    alignment should already be converted to numeric representation using\n",
    "    lett2num_.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      tX = projAlg(msa_num, Proj)\n",
    "    \"\"\"\n",
    "\n",
    "    N_seq, N_pos = alg.shape\n",
    "    N_aa = 20\n",
    "    al2d = np.array(alg2binss(alg).todense())\n",
    "    tX = np.zeros((N_seq, N_pos))\n",
    "    ProjMat = np.zeros((N_pos, N_aa))\n",
    "    for i in range(N_pos):\n",
    "        Projati = Proj[N_aa * i : N_aa * (i + 1)]\n",
    "        if sum(Projati ** 2) > 0:\n",
    "            Projati /= np.sqrt(sum(Projati ** 2))\n",
    "        ProjMat[i, :] = Projati\n",
    "        tX[:, i] = al2d[:, N_aa * i : N_aa * (i + 1)].dot(Projati.T)\n",
    "    return tX\n",
    "\n",
    "\n",
    "def projUpica(msa_ann, msa_num, seqw, kpos):\n",
    "    \"\"\"\n",
    "    Compute the projection of an alignment (msa_ann) on the kpos ICA components\n",
    "    of the SCA matrix of another (msa_num, seqw). This is useful to compare the\n",
    "    sequence space (as projected by the positional correlations) of one\n",
    "    alignment to another.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Upica_ann, Upica = projUpica(msa_ann, msa_num_ seqw, kpos)\n",
    "    \"\"\"\n",
    "\n",
    "    Csca, tX, Proj = scaMat(msa_num, seqw)\n",
    "    Vsca, Lsca = eigenVect(Csca)\n",
    "    Vpica, Wpica = rotICA(Vsca, kmax=kpos)\n",
    "    Usca = tX.dot(Vsca[:, :kpos]).dot(np.diag(1 / np.sqrt(Lsca[:kpos])))\n",
    "    tX_ann = projAlg(msa_ann, Proj)\n",
    "    Usca_ann = tX_ann.dot(Vsca[:, :kpos]).dot(\n",
    "        np.diag(1 / np.sqrt(Lsca[:kpos]))\n",
    "    )\n",
    "    Upica = Wpica.dot(Usca.T).T\n",
    "    Upica_ann = Wpica.dot(Usca_ann.T).T\n",
    "    for k in range(Upica.shape[1]):\n",
    "        Upica_ann[:, k] /= np.sqrt(Upica[:, k].T.dot(Upica[:, k]))\n",
    "        Upica[:, k] /= np.sqrt(Upica[:, k].T.dot(Upica[:, k]))\n",
    "    return Upica_ann, Upica\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# SECTOR ANALYSIS\n",
    "\n",
    "\n",
    "def sizeLargestCompo(adjMat):\n",
    "    \"\"\"\n",
    "    Compute the size of the largest component of a graph given its adjacency\n",
    "    matrix. Called by numConnected_ (Done by actually listing all the\n",
    "    components)\n",
    "\n",
    "    .. _numConnected: scaTools.html#scaTools.sizeLargestCompo\n",
    "\n",
    "    **Example**::\n",
    "      s = sizeLargestCompo(adjMat)\n",
    "\n",
    "    \"\"\"\n",
    "    Nnodes = adjMat.shape[0]\n",
    "    found = list()\n",
    "    components = list()\n",
    "    for node in range(Nnodes):\n",
    "        # If the node has not yet been encountered,\n",
    "        # it belongs to a new component:\n",
    "        if node not in found:\n",
    "            newcomponent = [node]\n",
    "            found.append(node)\n",
    "            i = 0\n",
    "            # Recursively listing the neighboors:\n",
    "            while i < len(newcomponent):\n",
    "                newneighbors = [\n",
    "                    j\n",
    "                    for j in range(Nnodes)\n",
    "                    if (\n",
    "                        adjMat[newcomponent[i], j] == 1\n",
    "                        and j not in newcomponent\n",
    "                    )\n",
    "                ]\n",
    "                newcomponent += newneighbors\n",
    "                found += newneighbors\n",
    "                i += 1\n",
    "            # Adding the new component to the list of all components:\n",
    "            components.append(newcomponent)\n",
    "    # Returning only the size of the maximal component:\n",
    "    return max([len(compo) for compo in components])\n",
    "\n",
    "\n",
    "def numConnected(\n",
    "    Vp, k, distmat, eps_list=np.arange(0.5, 0, -0.01), dcontact=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculates the number of positions in the largest connected component for\n",
    "    groups of positions i with :math:`V_p[i,k] > eps` and :math:`V_p[i,k] >\n",
    "    V_p[i,kk]`, for :math:`kk != k` and eps in eps_list. Useful for looking\n",
    "    evaluating the physical connectivity of different sectors or sub-sectors.\n",
    "\n",
    "    **Arguments**\n",
    "       :Vp: A set of eigenvectors or independent components\n",
    "       :k: The eigenvector or independent component to consider\n",
    "       :distmat: Distance matrix (computed by pdbSeq_)\n",
    "\n",
    "    .. _pdbSeq: scaTools.html#scaTools.pdbSeq\n",
    "\n",
    "    **Key Arguments**\n",
    "       :eps_list: the range of values of eps for which the group is non-empty\n",
    "       :dcontact: the distance cutoff for defining contacts\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "       eps_range, num_co, num_tot = numConnected(Vp, k, distmat, eps_list = np.arange(.5,0,-.01), dcontact=8)\n",
    "    \"\"\"\n",
    "\n",
    "    Npos = distmat.shape[0]\n",
    "    eps_range = list()\n",
    "    num_co = list()\n",
    "    num_tot = list()\n",
    "    [Npos, kmax] = Vp.shape\n",
    "    for eps in eps_list:\n",
    "        Vothers = [0 for i in range(Npos)]\n",
    "        for kk in range(kmax):\n",
    "            if kk != k:\n",
    "                Vothers = [max(Vothers[i], Vp[i, kk]) for i in range(Npos)]\n",
    "        group = [\n",
    "            i\n",
    "            for i in range(Npos)\n",
    "            if (Vp[i, k] > eps and Vp[i, k] > Vothers[i])\n",
    "        ]\n",
    "        eps_range.append(eps)\n",
    "        num_tot.append(len(group))\n",
    "        if len(group) > 0:\n",
    "            adjMat = distmat[np.ix_(group, group)] < dcontact\n",
    "            num_co.append(sizeLargestCompo(adjMat))\n",
    "        else:\n",
    "            num_co.append(0)\n",
    "    return eps_range, num_co, num_tot\n",
    "\n",
    "\n",
    "def chooseKpos(Lsca, Lrand):\n",
    "    \"\"\"\n",
    "    Given the eigenvalues of the sca matrix (Lsca), and the eigenvalues for the\n",
    "    set of randomized matrices (Lrand), return the number of significant\n",
    "    eigenmodes.\n",
    "    \"\"\"\n",
    "\n",
    "    return Lsca[Lsca > (Lrand[:, 1].mean() + (3 * Lrand[:, 1].std()))].shape[0]\n",
    "\n",
    "\n",
    "def icList(Vpica, kpos, Csca, p_cut=0.95):\n",
    "    \"\"\"\n",
    "    Produces a list of positions contributing to each independent component\n",
    "    (IC) above a defined statistical cutoff (p_cut, the cutoff on the CDF of\n",
    "    the t-distribution fit to the histogram of each IC). Any position above the\n",
    "    cutoff on more than one IC are assigned to one IC based on which group of\n",
    "    positions to which it shows a higher degree of coevolution. Additionally\n",
    "    returns the numeric value of the cutoff for each IC, and the pdf fit, which\n",
    "    can be used for plotting/evaluation.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      icList, icsize, sortedpos, cutoff, pd = icList(Vsca,Lsca,Lrand)\n",
    "    \"\"\"\n",
    "\n",
    "    # do the PDF/CDF fit, and assign cutoffs\n",
    "    Npos = len(Vpica)\n",
    "    cutoff = list()\n",
    "    scaled_pdf = list()\n",
    "    all_fits = list()\n",
    "    for k in range(kpos):\n",
    "        pd = t.fit(Vpica[:, k])\n",
    "        all_fits.append(pd)\n",
    "        iqr = scoreatpercentile(Vpica[:, k], 75) - scoreatpercentile(\n",
    "            Vpica[:, k], 25\n",
    "        )\n",
    "        binwidth = 2 * iqr * (len(Vpica[:, k]) ** (-0.33))\n",
    "        nbins = round((max(Vpica[:, k]) - min(Vpica[:, k])) / binwidth)\n",
    "        h_params = np.histogram(Vpica[:, k], int(nbins))\n",
    "        x_dist = np.linspace(min(h_params[1]), max(h_params[1]), num=100)\n",
    "        area_hist = Npos * (h_params[1][2] - h_params[1][1])\n",
    "        scaled_pdf.append(area_hist * (t.pdf(x_dist, pd[0], pd[1], pd[2])))\n",
    "        cd = t.cdf(x_dist, pd[0], pd[1], pd[2])\n",
    "        tmp = scaled_pdf[k].argmax()\n",
    "        if abs(max(Vpica[:, k])) > abs(min(Vpica[:, k])):\n",
    "            tail = cd[tmp : len(cd)]\n",
    "        else:\n",
    "            cd = 1 - cd\n",
    "            tail = cd[0:tmp]\n",
    "        diff = abs(tail - p_cut)\n",
    "        x_pos = diff.argmin()\n",
    "        cutoff.append(x_dist[x_pos + tmp])\n",
    "\n",
    "    # select the positions with significant contributions to each IC\n",
    "    ic_init = list()\n",
    "    for k in range(kpos):\n",
    "        ic_init.append([i for i in range(Npos) if Vpica[i, k] > cutoff[k]])\n",
    "\n",
    "    # construct the sorted, non-redundant iclist\n",
    "    sortedpos = list()\n",
    "    icsize = list()\n",
    "    ics = list()\n",
    "    icpos_tmp = list()\n",
    "    Csca_nodiag = Csca.copy()\n",
    "    for i in range(Npos):\n",
    "        Csca_nodiag[i, i] = 0\n",
    "    for k in range(kpos):\n",
    "        icpos_tmp = list(ic_init[k])\n",
    "        for kprime in [kp for kp in range(kpos) if kp != k]:\n",
    "            tmp = [v for v in icpos_tmp if v in ic_init[kprime]]\n",
    "            for i in tmp:\n",
    "                remsec = np.linalg.norm(\n",
    "                    Csca_nodiag[i, ic_init[k]]\n",
    "                ) < np.linalg.norm(Csca_nodiag[i, ic_init[kprime]])\n",
    "                if remsec:\n",
    "                    icpos_tmp.remove(i)\n",
    "        sortedpos += sorted(icpos_tmp, key=lambda i: -Vpica[i, k])\n",
    "        icsize.append(len(icpos_tmp))\n",
    "        s = Unit()\n",
    "        s.items = sorted(icpos_tmp, key=lambda i: -Vpica[i, k])\n",
    "        s.col = k / kpos\n",
    "        s.vect = -Vpica[s.items, k]\n",
    "        ics.append(s)\n",
    "    return ics, icsize, sortedpos, cutoff, scaled_pdf, all_fits\n",
    "\n",
    "\n",
    "def singleBar(x, loc, cols, width=0.5):\n",
    "    \"\"\"\n",
    "    Single bar diagram, called by MultiBar_.\n",
    "\n",
    "    .. _MultiBar: scaTools.html#scaTools.MultiBar\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      singleBar(x, loc, cols, width=.5)\n",
    "    \"\"\"\n",
    "\n",
    "    s = 0\n",
    "    y = list()\n",
    "    for i, v in enumerate(x):\n",
    "        s += v\n",
    "        y.append(s)\n",
    "    for i, v in enumerate(x):\n",
    "        plt.bar(loc, y[len(x) - i - 1], width, color=cols[len(x) - i - 1])\n",
    "\n",
    "\n",
    "def MultiBar(x, colors=\"wbrgymc\", width=0.5):\n",
    "    \"\"\"\n",
    "    Multiple bar diagram (plots contributions to each bar from different\n",
    "    elements in x as different colors). This can be useful if you'd like to\n",
    "    inspect how sector positions are distributed among independent\n",
    "    components/eigenmodes. The argument x is a tuple, specifying the number of\n",
    "    elements in each bar to be each color. The example below makes a graph with\n",
    "    four bars, where the first bar has 99 white elements, 1 blue element and 1\n",
    "    red element.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      x = [[99, 1, 1], [6, 13, 2], [0, 0, 13], [1, 7, 5]]\n",
    "      sca.MultiBar(x)\n",
    "    \"\"\"\n",
    "    for i, v in enumerate(x):\n",
    "        singleBar(v, i, cols=colors)\n",
    "    plt.xticks(\n",
    "        np.arange(len(x)) + width / 2.0,\n",
    "        [\"S%i\" % i for i in range(len(x))],\n",
    "        fontsize=14,\n",
    "    )\n",
    "    plt.axis([-width / 2, len(x) - width / 2, 0, max([sum(v) for v in x]) + 5])\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# DIRECT COUPLING ANALYSIS (DCA)\n",
    "\n",
    "\n",
    "class Pair:\n",
    "    \"\"\"\n",
    "    A class for a pair of positions.\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "      :pos:  a pair of amino acid positions (ex: [1,3], supplied as argument p)\n",
    "      :DI:   the direct information between the two positions (argument x)\n",
    "      :dist: the physical distance between the positions (argument d)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p, x, d):\n",
    "        self.pos = p\n",
    "        self.DI = x\n",
    "        self.dist = d\n",
    "\n",
    "\n",
    "def directInfo(freq1, freq2, lbda=0.5, freq0=np.ones(20) / 21, Naa=20):\n",
    "    \"\"\"\n",
    "    Calculate direct information as in the Direct Coupling Analysis (DCA)\n",
    "    method proposed by M. Weigt et collaborators (Ref: Marcos et al, PNAS 2011,\n",
    "    108: E1293-E1301).\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      DI = directInfo(freq1, freq2, lbda=.5, freq0=np.ones(20)/21, Naa=20)\n",
    "    \"\"\"\n",
    "    Npos = int(len(freq1) / Naa)\n",
    "    Cmat_dat = freq2 - np.outer(freq1, freq1)\n",
    "\n",
    "    # Background:\n",
    "    block = np.diag(freq0) - np.outer(freq0, freq0)\n",
    "    Cmat_bkg = np.zeros((Npos * Naa, Npos * Naa))\n",
    "    for i in range(Npos):\n",
    "        Cmat_bkg[Naa * i : Naa * (i + 1), Naa * i : Naa * (i + 1)] = block\n",
    "\n",
    "    # Regularizations:\n",
    "    Cmat = (1 - lbda) * Cmat_dat + lbda * Cmat_bkg\n",
    "    frq = (1 - lbda) * freq1 + lbda * np.tile(freq0, Npos)\n",
    "\n",
    "    # DI at mean-field approx:\n",
    "    Jmat = -np.linalg.inv(Cmat)\n",
    "    DI = np.zeros((Npos, Npos))\n",
    "    for i in range(Npos):\n",
    "        for j in range(i + 1, Npos):\n",
    "            DI[i, j] = dirInfoFromJ(i, j, Jmat, frq, Naa)\n",
    "            DI[j, i] = DI[i, j]\n",
    "    return DI\n",
    "\n",
    "\n",
    "def dirInfoFromJ(i, j, Jmat, frq, Naa=20, epsilon=1e-4):\n",
    "    \"\"\"\n",
    "    Direct information from the matrix of couplings :math:`J_{ij}` (called by\n",
    "    directInfo_). Ref: Marcos et al, PNAS 2011, 108: E1293-E1301\n",
    "\n",
    "    .. _directInfo: scaTools.html#scaTools.directInfo\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "     :i: position 1\n",
    "     :j: position 2\n",
    "     :Jmat: coupling matrix\n",
    "     :frq: frequency\n",
    "     :Naa: number of amino acids\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      DI = dirInfoFromJ(i, j, Jmat, frq, Naa=20, epsilon=1e-4)\n",
    "    \"\"\"\n",
    "\n",
    "    W = np.ones((Naa + 1, Naa + 1))\n",
    "    W[:Naa, :Naa] = np.exp(\n",
    "        Jmat[Naa * i : Naa * (i + 1), Naa * j : Naa * (j + 1)]\n",
    "    )\n",
    "    mui = np.ones(Naa + 1) / (Naa + 1)\n",
    "    muj = np.ones(Naa + 1) / (Naa + 1)\n",
    "    pi = np.zeros(Naa + 1)\n",
    "    pi[:Naa] = frq[Naa * i : Naa * (i + 1)]\n",
    "    pi[Naa] = 1 - sum(pi)\n",
    "    pj = np.zeros(Naa + 1)\n",
    "    pj[:Naa] = frq[Naa * j : Naa * (j + 1)]\n",
    "    pj[Naa] = 1 - sum(pj)\n",
    "    diff = epsilon + 1\n",
    "    while diff > epsilon:\n",
    "        scrai = muj.dot(W.T)\n",
    "        scraj = mui.dot(W)\n",
    "        newi = pi / scrai\n",
    "        newi /= newi.sum()\n",
    "        newj = pj / scraj\n",
    "        newj /= newj.sum()\n",
    "        diff = max(abs(newi - mui).max(), abs(newj - muj).max())\n",
    "        mui = newi\n",
    "        muj = newj\n",
    "    Pdir = W * np.outer(mui, muj)\n",
    "    Pdir /= Pdir.sum()\n",
    "    Pfac = np.outer(pi, pj)\n",
    "    tiny = 1e-100\n",
    "    return np.trace(Pdir.T.dot(np.log((Pdir + tiny) / (Pfac + tiny))))\n",
    "\n",
    "\n",
    "def truncDiag(M, dmax):\n",
    "    \"\"\"\n",
    "    Set to 0 the elements of a matrix M up to a distance dmax from the\n",
    "    diagonal.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Mtr = truncDiag(M, dmax)\n",
    "    \"\"\"\n",
    "\n",
    "    Mtr = copy.copy(M)\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(i, min(i + dmax + 1, M.shape[1])):\n",
    "            Mtr[i, j] = 0\n",
    "            Mtr[j, i] = 0\n",
    "    return Mtr\n",
    "\n",
    "\n",
    "class Secton:\n",
    "    \"\"\"\n",
    "    A class for sectons.\n",
    "\n",
    "    **Attributes**\n",
    "\n",
    "      :pos: a list of positions\n",
    "      :num: number of positions in the secton\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, positions):\n",
    "        self.pos = positions\n",
    "        self.num = len(positions)\n",
    "\n",
    "    def dist(self, distmat):\n",
    "        \"\"\" returns the distance between the position pair\"\"\"\n",
    "        return distmat[np.ix_(self.pos, self.pos)]\n",
    "\n",
    "    def connected(self, distmat, threshold):\n",
    "        \"\"\"\n",
    "        Check the structural connectivity based on the principle that if\n",
    "        :math:`M_{ij}` is the adjacency matrix of a graph, :math:`M^n_{ij}` is\n",
    "        the number of paths of length :math:`n` between i and j, which must be\n",
    "        > 0 for :math:`n` = number of nodes when i and j are in the same\n",
    "        connected component.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            np.linalg.matrix_power(self.dist(distmat) < threshold, self.num)\n",
    "            > 0\n",
    "        ).sum() / self.num ** 2 == 1\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# RANDOMIZATION\n",
    "\n",
    "\n",
    "def randAlg(frq, Mseq):\n",
    "    \"\"\"\n",
    "    Generate a random alignment with Mseq sequences based on the frequencies\n",
    "    frq[i,a] of amino acids with a = 0,1,...,Naa (0 for gaps).\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      msa_rand = randAlg(frq, Mseq)\n",
    "    \"\"\"\n",
    "\n",
    "    Npos = frq.shape[0]\n",
    "    msa_rand = np.zeros((Mseq, Npos), dtype=int)\n",
    "    for i in range(Npos):\n",
    "        Maa = np.random.multinomial(Mseq, frq[i, :])\n",
    "        col = np.array([], dtype=int)\n",
    "        for aa, M in enumerate(Maa):\n",
    "            col = np.append(col, np.tile(aa, M))\n",
    "        np.random.shuffle(col)\n",
    "        msa_rand[:, i] = col\n",
    "    return msa_rand\n",
    "\n",
    "\n",
    "def randomize(\n",
    "    msa_num,\n",
    "    Ntrials,\n",
    "    seqw=1,\n",
    "    norm=\"frob\",\n",
    "    lbda=0,\n",
    "    Naa=20,\n",
    "    kmax=6,\n",
    "    tolerance=1e-12,\n",
    "):\n",
    "    \"\"\"\n",
    "    Randomize the alignment while preserving the frequencies of amino acids at\n",
    "    each position and compute the resulting spectrum of the SCA matrix.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "     :msa_num: a MxL sequence alignment (converted to numerical representation\n",
    "               using lett2num_)\n",
    "     :Ntrials: number of trials\n",
    "     :seqw: vector of sequence weights (default is to assume equal weighting)\n",
    "     :norm: either 'frob' (frobenius) or 'spec' (spectral)\n",
    "     :lbda: lambda parameter for setting the frequency of pseudo-counts (0 for\n",
    "            no pseudo counts)\n",
    "     :Naa: number of amino acids\n",
    "     :kmax: number of eigenvectors to keep for each randomized trial\n",
    "     :tolerance: workaround for roundoff error that occurs when calculating gap\n",
    "                 probability fr0\n",
    "\n",
    "    **Returns**\n",
    "\n",
    "     :Vrand: eigenvectors for the :math:`\\\\tilde {C_{ij}^{ab}}` matrix of\n",
    "             the randomized alignment (dimensions: Ntrials*Npos*kmax)\n",
    "     :Lrand: eigenvalues for the :math:`\\\\tilde {C_{ij}^{ab}}` matrix of\n",
    "             the randomized alignment  (dimensions: Ntrials*Npos)\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Vrand, Lrand, Crand = randomize(msa_num, 10, seqw, Naa=20, kmax=6)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(seqw, int) and seqw == 1:\n",
    "        seqw = np.ones((1, Nseq))\n",
    "    Mseq = np.round(seqw.sum()).astype(int)\n",
    "    Nseq, Npos = msa_num.shape\n",
    "    Crnd = np.zeros((Npos, Npos))\n",
    "\n",
    "    # Weighted frequencies, including gaps:\n",
    "    f1, f2, f0 = freq(\n",
    "        msa_num, Naa=20, seqw=seqw, lbda=lbda, freq0=np.ones(20) / 21\n",
    "    )\n",
    "    fr1 = np.reshape(f1, (Npos, Naa))\n",
    "    fr0 = (1.0 - fr1.sum(axis=1)).reshape(Npos, 1)\n",
    "\n",
    "    # workaround for roundoff errors giving freq < 0 or > 1\n",
    "    fr0[fr0 < tolerance] = 0\n",
    "    fr0[(fr0 > 1) * ((fr0 - tolerance) < 1)] = 1\n",
    "    fr1[fr1 < tolerance] = 0\n",
    "    fr1[(fr1 > 1) * ((fr1 - tolerance) < 1)] = 1\n",
    "\n",
    "    fr01 = np.concatenate((fr0, fr1), axis=1)\n",
    "\n",
    "    # Multiple randomizations:\n",
    "    Vrand = np.zeros((Ntrials, Npos, kmax))\n",
    "    Lrand = np.zeros((Ntrials, Npos))\n",
    "    for t in range(Ntrials):\n",
    "        msa_rand = randAlg(fr01, Mseq)\n",
    "        Csca = scaMat(msa_rand, norm=norm, lbda=lbda)[0]\n",
    "        Crnd += Csca\n",
    "        V, L = eigenVect(Csca)\n",
    "        Vrand[t, :, :] = V[:, :kmax]\n",
    "        Lrand[t, :] = L\n",
    "    Crnd = Crnd / Ntrials\n",
    "    return Vrand, Lrand, Crnd\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# DISPLAY\n",
    "\n",
    "\n",
    "def figWeights(U1, U2, weight):\n",
    "    \"\"\"\n",
    "     A 2d scatter plot with color indicating weight.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      figWeights(U1, U2, weight)\n",
    "    \"\"\"\n",
    "\n",
    "    seqcol = -np.log(weight)\n",
    "    seqcol = (seqcol - min(seqcol) + 1) / (max(seqcol) - min(seqcol) + 1)\n",
    "    seqorder = sorted(range(len(seqcol)), key=lambda s: seqcol[s])\n",
    "    for s in seqorder:\n",
    "        plt.plot(\n",
    "            U1[s],\n",
    "            U2[s],\n",
    "            \"o\",\n",
    "            color=cm.jet(seqcol[s], 1),\n",
    "            markeredgecolor=\"none\",\n",
    "        )\n",
    "\n",
    "\n",
    "def figColors():\n",
    "    \"\"\"\n",
    "    Color code for figUnits_.\n",
    "\n",
    "    .. _figUnits: scaTools.html#scaTools.figUnits\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      figColors()\n",
    "    \"\"\"\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = 6, 6\n",
    "    for s in np.arange(0, 1, 0.05):\n",
    "        for a in np.arange(0, 1, 0.01):\n",
    "            bgr = colorsys.hsv_to_rgb(a, s, 1)\n",
    "            plt.plot(\n",
    "                s * np.cos(2 * np.pi * a),\n",
    "                s * np.sin(2 * np.pi * a),\n",
    "                \"o\",\n",
    "                markersize=8,\n",
    "                markerfacecolor=bgr,\n",
    "                markeredgecolor=bgr,\n",
    "            )\n",
    "    plt.title(\n",
    "        r\"Color at angle $\\alpha$ encoded with $\\alpha/(2\\pi)$.\", fontsize=16\n",
    "    )\n",
    "    plt.axis([-1.1, 1.1, -1.1, 1.1])\n",
    "\n",
    "\n",
    "def figUnits(v1, v2, units, marker=\"o\", dotsize=9, notinunits=1):\n",
    "    \"\"\"\n",
    "    2d scatter plot specified by 'units', which must be a list of elements in\n",
    "    the class Unit_. See figColors_ for the color code. Admissible color codes\n",
    "    are in [0 1] (light/dark gray can also be obtained by using -1/+1).  For\n",
    "    instance: 0->red, 1/3->green, 2/3-> blue.\n",
    "\n",
    "    .. _Unit: scaTools.html#scaTools.Unit\n",
    "    .. _figColors: scaTools.html#scaTools.figColors\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "      :v1: xvals\n",
    "      :v2: yvals\n",
    "      :units: list of elements in units\n",
    "\n",
    "    **Key Arguments**\n",
    "\n",
    "      :marker: plot marker symbol\n",
    "      :dotsize: specify marker/dotsize\n",
    "      :notinunits:\n",
    "        - if set to 1: the elements not in a unit are represented in white\n",
    "        - if set to 0 these elements are not represented\n",
    "        - if set to [w1,w2] : elements with coordinates w1,w2 are represented\n",
    "          in white in the background.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      figUnits(v1, v2, units, marker='o', gradcol=0, dotsize=9, notinunits=1)\n",
    "    \"\"\"\n",
    "\n",
    "    # Plot all items in white:\n",
    "    if notinunits == 1:\n",
    "        plt.plot(\n",
    "            v1,\n",
    "            v2,\n",
    "            marker,\n",
    "            markersize=dotsize,\n",
    "            markerfacecolor=\"w\",\n",
    "            markeredgecolor=\"k\",\n",
    "        )\n",
    "    elif len(notinunits) == 2:\n",
    "        plt.plot(\n",
    "            notinunits[0],\n",
    "            notinunits[1],\n",
    "            marker,\n",
    "            markersize=dotsize,\n",
    "            markerfacecolor=\"w\",\n",
    "            markeredgecolor=\"k\",\n",
    "        )\n",
    "    # Plot items in the units with colors:\n",
    "    for u in units:\n",
    "        items_list = list(u.items)\n",
    "        if u.col >= 0 and u.col < 1:\n",
    "            bgr = colorsys.hsv_to_rgb(u.col, 1, 1)\n",
    "        if u.col == 1:\n",
    "            bgr = [0.3, 0.3, 0.3]\n",
    "        if u.col < 0:\n",
    "            bgr = [0.7, 0.7, 0.7]\n",
    "        plt.plot(\n",
    "            v1[np.ix_(items_list)],\n",
    "            v2[np.ix_(items_list)],\n",
    "            marker,\n",
    "            markersize=dotsize,\n",
    "            markerfacecolor=bgr,\n",
    "            markeredgecolor=\"k\",\n",
    "        )\n",
    "\n",
    "\n",
    "def figMapping(Csca, tX, kpos, sectors, subfam):\n",
    "    \"\"\"\n",
    "    Function that automates finding the top :math:`k_{pos}` independent\n",
    "    components, projection, and plotting.\n",
    "\n",
    "    Useful to get a representation of the sectors/subfamilies mapping for a\n",
    "    given kpos.\n",
    "\n",
    "    **Arguments**\n",
    "\n",
    "       :Csca: the sca matrix\n",
    "       :tX: the projected alignment\n",
    "       :kpos: the number of independent components to consider\n",
    "       :sectors: list of Unit_ elements for each sector\n",
    "       :subfam: list of Unit_ elements for each sequence family\n",
    "\n",
    "    **Returns**\n",
    "\n",
    "       :Vpica: the independent components of Csca\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      Vpica = figMapping(Csca, tX, kpos, sectors, subfam)\n",
    "    \"\"\"\n",
    "\n",
    "    Vsca, Lsca = eigenVect(Csca)\n",
    "    Vpica, Wpica = rotICA(Vsca, kmax=kpos)\n",
    "    Usca = tX.dot(Vsca[:, :kpos]).dot(np.diag(1 / np.sqrt(Lsca[:kpos])))\n",
    "    Upica = Wpica.dot(Usca.T).T\n",
    "    for k in range(Upica.shape[1]):\n",
    "        Upica[:, k] /= np.sqrt(Upica[:, k].T.dot(Upica[:, k]))\n",
    "    Usica, Wsica = rotICA(Usca, kmax=kpos)\n",
    "    pairs = [[i, i + 1] for i in [j for j in range(kpos - 1) if (j % 2 == 0)]]\n",
    "    if kpos % 2 == 1:\n",
    "        pairs.append([kpos - 1, 0])\n",
    "    plt.rcParams[\"figure.figsize\"] = (4 * len(pairs)) + 1, 8\n",
    "    for n, [k1, k2] in enumerate(pairs):\n",
    "        plt.subplot(2, len(pairs), n + 1)\n",
    "        figUnits(Vpica[:, k1], Vpica[:, k2], sectors)\n",
    "        plt.xlabel(r\"$V^p_{%i}$\" % (k1 + 1), fontsize=16)\n",
    "        plt.ylabel(r\"$V^p_{%i}$\" % (k2 + 1), fontsize=16)\n",
    "        plt.subplot(2, len(pairs), n + len(pairs) + 1)\n",
    "        figUnits(Upica[:, k1], Upica[:, k2], subfam, marker=\"D\")\n",
    "        plt.xlabel(r\"$U^p_{%i}$\" % (k1 + 1), fontsize=16)\n",
    "        plt.ylabel(r\"$U^p_{%i}$\" % (k2 + 1), fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    return Vpica\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# PDB PROCESSING\n",
    "\n",
    "\n",
    "def pdbSeq(pdbid, chain=\"A\", path2pdb=settings.path2structures, calcDist=1):\n",
    "    \"\"\"\n",
    "    Extract sequence, position labels and matrix of distances from a PDB file.\n",
    "\n",
    "    **Arguments**\n",
    "      :pdbid: PDB identifier (four letters/numbers)\n",
    "      :chain: PDB chain identifier\n",
    "      :path2pdb: location of the PDB file\n",
    "      :calcDist: calculate a distance matrix between all pairs of positions,\n",
    "                 default is 1\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      sequence, labels, dist = pdbSeq(pdbid, chain='A', path2pdb)\n",
    "    \"\"\"\n",
    "\n",
    "    # Table of 3-letter to 1-letter code for amino acids\n",
    "    aatable = {\n",
    "        \"ALA\": \"A\",\n",
    "        \"ARG\": \"R\",\n",
    "        \"ASN\": \"N\",\n",
    "        \"ASP\": \"D\",\n",
    "        \"CYS\": \"C\",\n",
    "        \"GLN\": \"Q\",\n",
    "        \"GLU\": \"E\",\n",
    "        \"GLY\": \"G\",\n",
    "        \"HIS\": \"H\",\n",
    "        \"ILE\": \"I\",\n",
    "        \"LEU\": \"L\",\n",
    "        \"LYS\": \"K\",\n",
    "        \"MET\": \"M\",\n",
    "        \"PHE\": \"F\",\n",
    "        \"PRO\": \"P\",\n",
    "        \"SER\": \"S\",\n",
    "        \"THR\": \"T\",\n",
    "        \"TRP\": \"W\",\n",
    "        \"TYR\": \"Y\",\n",
    "        \"VAL\": \"V\",\n",
    "    }\n",
    "\n",
    "    # Read PDB structure:\n",
    "    P = PDBParser(PERMISSIVE=1)\n",
    "    structure = P.get_structure(pdbid, os.path.join(path2pdb, pdbid) + \".pdb\")\n",
    "\n",
    "    # Fill up sequence and label information\n",
    "    sequence = \"\"\n",
    "    labels = list()\n",
    "    residues = [res for res in structure[0][chain] if res.get_id()[0] == \" \"]\n",
    "    for res in residues:\n",
    "        labels.append(str(res.get_id()[1]) + str(res.get_id()[2]).strip())\n",
    "        try:\n",
    "            sequence += aatable[res.get_resname()]\n",
    "        except BaseException as e:\n",
    "            print(\"Error: \" + str(e))\n",
    "            sequence += \"X\"\n",
    "\n",
    "    # Distances between residues (minimal distance between atoms, in angstrom):\n",
    "    dist = np.zeros((len(residues), len(residues)))\n",
    "    if calcDist == 1:\n",
    "        for n0, res0 in enumerate(residues):\n",
    "            for n1, res1 in enumerate(residues):\n",
    "                dist[n0, n1] = min(\n",
    "                    [atom0 - atom1 for atom0 in res0 for atom1 in res1]\n",
    "                )\n",
    "        return sequence, labels, dist\n",
    "    else:\n",
    "        return sequence, labels\n",
    "\n",
    "\n",
    "def writePymol(\n",
    "    pdb,\n",
    "    sectors,\n",
    "    ics,\n",
    "    ats,\n",
    "    outfilename,\n",
    "    chain=\"A\",\n",
    "    inpath=settings.path2structures,\n",
    "    quit=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Write basic a pymol script for displaying sectors and exporting an image.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      writePymol(pdb, sectors, ics, ats, outfilename, chain='A',inpath=settings.path2structures, quit=1)\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(outfilename, \"w\")\n",
    "    f.write(\"delete all\\n\")\n",
    "    f.write(\"load %s%s.pdb, main\\n\" % (inpath, pdb))\n",
    "    f.write(\"hide all\\n\")\n",
    "    f.write(\"bg_color white\\n\")\n",
    "    f.write(\"show cartoon, (chain %s)\\n\" % chain)\n",
    "    f.write(\"color white\\n\\n\")\n",
    "    for k, sec in enumerate(sectors):\n",
    "        b, g, r = colorsys.hsv_to_rgb(sec.col, 1, 1)\n",
    "        f.write(\"set_color color%i, [%.3f,%.3f,%.3f]\\n\" % (k + 1, b, g, r))\n",
    "        f.write(\n",
    "            \"create sector%i, (resi %s) & (chain %s)\\n\"\n",
    "            % (k + 1, \",\".join([ats[s] for s in sec.items]), chain)\n",
    "        )\n",
    "        f.write(\"color color%i, sector%i\\n\" % (k + 1, k + 1))\n",
    "        f.write(\"show spheres, sector%i\\n\" % (k + 1))\n",
    "        f.write(\"show surface, sector%i\\n\\n\" % (k + 1))\n",
    "    for k, sec in enumerate(ics):\n",
    "        b, g, r = colorsys.hsv_to_rgb(sec.col, 1, 1)\n",
    "        f.write(\"set_color color_ic%i, [%.3f,%.3f,%.3f]\\n\" % (k + 1, b, g, r))\n",
    "        f.write(\n",
    "            \"create ic_%i, (resi %s) & (chain %s)\\n\"\n",
    "            % (k + 1, \",\".join([ats[s] for s in sec.items]), chain)\n",
    "        )\n",
    "        f.write(\"color color_ic%i, ic_%i\\n\" % (k + 1, k + 1))\n",
    "        f.write(\"show spheres, ic_%i\\n\" % (k + 1))\n",
    "        f.write(\"show surface, ic_%i\\n\\n\" % (k + 1))\n",
    "    f.write(\"zoom\\n\")\n",
    "    f.write(\"set transparency, 0.4\\n\")\n",
    "    f.write(\"ray\\n\")\n",
    "    path_list = outfilename.split(os.sep)\n",
    "    fn = path_list[-1]\n",
    "    f.write(\"png %s\\n\" % fn.replace(\".pml\", \"\"))\n",
    "    if quit == 1:\n",
    "        f.write(\"quit\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def figStruct(\n",
    "    pdbid,\n",
    "    sectors,\n",
    "    ics,\n",
    "    ats,\n",
    "    chainid=\"A\",\n",
    "    outfile=settings.path2output + \"sectors.pml\",\n",
    "    quit=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Make and display an image of the sectors (within a python notebook). By\n",
    "    default quit PyMol after running it, unless the option 'quit=0' is given.\n",
    "    The default name and location of the output can also be changed.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      figStruct(pdbid, sectors, ats, chainid='A', outfile = settings.path2output+'sectors.pml', quit=1)\n",
    "    \"\"\"\n",
    "\n",
    "    writePymol(\n",
    "        pdbid, sectors, ics, ats, outfilename=outfile, chain=chainid, quit=1\n",
    "    )\n",
    "    if settings.path2pymol:\n",
    "        os.system(settings.path2pymol + \" \" + outfile)\n",
    "    else:\n",
    "        os.system(\"pymol\" + \" \" + outfile)\n",
    "    img = mpimg.imread(outfile.replace(\".pml\", \".png\"))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "##########################################################################\n",
    "# CYTOSCAPE OUTPUT\n",
    "\n",
    "\n",
    "def cytoscapeOut(ats, cutoff, Csca, Di, sectors, Vp, outfilename):\n",
    "    \"\"\"\n",
    "    Output tab-delimited text that can be read in by cytoscape. The goal is to\n",
    "    enable graph representations of the SCA couplings, where residues are\n",
    "    nodes, and couplings are edges. Within cytoscape, the graph can be\n",
    "    color-coded or weighted by Csca, Di, sector definition or Vp.\n",
    "\n",
    "    **Example**::\n",
    "\n",
    "      cytoscapeOut(ats, cutoff, Csca, Di, sectors, Vp, outfilename)\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(outfilename + \".sif\", \"w\")\n",
    "    for k in range(len(ats)):\n",
    "        flag = 0\n",
    "        for j in range(k + 1, len(ats)):\n",
    "            if Csca[k][j] > cutoff:\n",
    "                f.write(ats[k] + \" aa \" + ats[j] + \"\\n\")\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            f.write(ats[k] + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "    f = open(outfilename + \".eda\", \"w\")\n",
    "    f.write(\"KEY\\tSCA\\n\")\n",
    "    for k in range(len(ats)):\n",
    "        for j in range(k + 1, len(ats)):\n",
    "            f.write((ats[k] + \" (aa) \" + ats[j] + \"\\t  %.4f \\n\") % Csca[k][j])\n",
    "    f.close()\n",
    "\n",
    "    s_idx = [0 for k in range(len(ats))]\n",
    "    for i, j in enumerate(sectors):\n",
    "        for k in j.items:\n",
    "            s_idx[k] = i + 1\n",
    "\n",
    "    f = open(outfilename + \".noa\", \"w\")\n",
    "    f.write(\"KEY\\tCONSERVATION\\tSector\\tVp1\\tVp2\\tVp3\\n\")\n",
    "    for j, k in enumerate(ats):\n",
    "        f.write(\n",
    "            (k + \"\\t %.4f \\t %i \\t %.4f \\t %.4f \\t %.4f \\n\")\n",
    "            % (Di[j], s_idx[j], Vp[j, 0], Vp[j, 1], Vp[j, 2])\n",
    "        )\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
